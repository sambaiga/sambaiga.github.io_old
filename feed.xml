<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://sambaiga.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sambaiga.github.io/" rel="alternate" type="text/html" /><updated>2019-01-15T06:34:07+01:00</updated><id>https://sambaiga.github.io/feed.xml</id><title type="html">sambaiga</title><author><name>Anthony Faustine</name></author><entry><title type="html">Stochastic Variational Inference (SVI) in Pyro</title><link href="https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/14/stochastic_variational_bayes_pyro.html" rel="alternate" type="text/html" title="Stochastic Variational Inference (SVI) in Pyro" /><published>2018-11-14T16:12:00+01:00</published><updated>2018-11-16T08:35:54+01:00</updated><id>https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/14/stochastic_variational_bayes_pyro</id><content type="html" xml:base="https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/14/stochastic_variational_bayes_pyro.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://pyro.ai/&quot;&gt;Pyro&lt;/a&gt; is a deep universal probabilistic programming  library  built on &lt;a href=&quot;https://pytorch.org/&quot;&gt;Pytorch&lt;/a&gt;. Developed by &lt;a href=&quot;http://uber.ai/&quot;&gt;Uber AI lab&lt;/a&gt; with focus to  unify the best of modern deep learning and well established bayesian modeling. It can represent any computable probability distribution using &lt;a href=&quot;https://pytorch.org/docs/master/distributions.html&quot;&gt;torch.distribution&lt;/a&gt; packages that contains parameterizable probability distributions and sampling functions. The example  below define a unit normal distribution &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(0,1)&lt;/script&gt;, draw  sample &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; from &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(0,1)&lt;/script&gt; and compute the log probability according to the distribution.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyro.distributions&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;# draw a sample from N(0,1)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;#compute the log probability according to the distribution
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sample&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;log prob&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_prob&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Models parameters to be optimized are introduced using  &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.param()&lt;/code&gt; statements while stochastic choices uses &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.sample()&lt;/code&gt;. &lt;a href=&quot;http://docs.pyro.ai/en/0.2.1-release/parameters.html&quot;&gt;Parameters&lt;/a&gt; play a central role in stochastic variational inference, where they are used to represent point estimates for the parameters in parameterized families of models and varitional distribution (guides). The &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.sample&lt;/code&gt; is used for calling a &lt;em&gt;named&lt;/em&gt; primitive stochastic function. Both &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.sample&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.param&lt;/code&gt; are always called with a &lt;em&gt;name&lt;/em&gt; as its first argument. The Pyro’s backend uses these names to uniquely identify sample statements and change their behavior at runtime. Consider the following Beta-Bernoulli model.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x, \theta)= \mathrm{Beta}(\theta | 1,1)\prod_{i=1}^{50} \mathrm{Bernoulli}(x_i | \theta)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is a probability shared across &lt;script type=&quot;math/tex&quot;&gt;50&lt;/script&gt; data points &lt;script type=&quot;math/tex&quot;&gt;x \in \{0,1\}&lt;/script&gt;.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyro&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;theta&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyro&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;stochastic-variational-inference-svi-with-pyro&quot;&gt;Stochastic Variational Inference (SVI) with Pyro&lt;/h3&gt;

&lt;p&gt;Pyro has been designed with particular attention to supporting stochastic variational inference as a general purpose inference algorithm. Consider probability model with observations &lt;script type=&quot;math/tex&quot;&gt;{\bf x}&lt;/script&gt; and latent random variables &lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}&lt;/script&gt; as well as parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and  a joint probability density of the form
&lt;script type=&quot;math/tex&quot;&gt;p_{\theta}({\bf x}, {\bf z}) = p_{\theta}({\bf x}|{\bf z}) p_{\theta}({\bf z})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;To draw inference on the latent variable &lt;script type=&quot;math/tex&quot;&gt;{\bf z}&lt;/script&gt; we compute the posterior&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\theta}({\bf z}|{\bf x}) = \frac{p_{\theta}({\bf x},{\bf z})}{p_{\theta}({\bf z})} = \frac{p_{\theta}({\bf x}|{\bf z})\cdot p_{\theta}({\bf z})}{p({\bf x})}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p_{\theta}({\bf x})=\int p_{\theta}({\bf x}|{\bf z})\cdot p_{\theta}(\mathbf{z}) dz&lt;/script&gt;

&lt;p&gt;Variational inference offers a scheme for finding model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and computing an approximation to the posterior &lt;script type=&quot;math/tex&quot;&gt;p_{\theta}(\mathbf{z}\mid {\bf x})&lt;/script&gt; by introducing a parameterized distribution &lt;script type=&quot;math/tex&quot;&gt;q_{\lambda}(\mathbf{z})&lt;/script&gt; where  &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is the variational parameters. This distribution is called the variational distribution however in the context of Pyro it’s called the &lt;a href=&quot;&quot;&gt;guide&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://docs.pyro.ai/en/0.2.1-release/inference.html&quot;&gt;SVI class&lt;/a&gt; is the unified interface for SVI in Pyro. To use this class you need to provide: the &lt;em&gt;model&lt;/em&gt;,  the &lt;em&gt;guide&lt;/em&gt;, and an &lt;em&gt;optimizer&lt;/em&gt;. To implement SVI in pyro we have to specifies &lt;script type=&quot;math/tex&quot;&gt;q_{\lambda}(\mathbf{z})&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p_{\theta}(\mathbf{z}\mid {\bf x})&lt;/script&gt; through guide and model function which takes the same data as parameter. The &lt;a href=&quot;&quot;&gt;guide&lt;/a&gt; &lt;script type=&quot;math/tex&quot;&gt;q_{\lambda}(\mathbf{z})&lt;/script&gt; in pyro serve as an approximation to the posterior &lt;script type=&quot;math/tex&quot;&gt;p_{\theta}(\mathbf{z}\mid {\bf x})&lt;/script&gt;.The &lt;code class=&quot;highlighter-rouge&quot;&gt;model()&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;guide()&lt;/code&gt; should take the same arguments even if the distributions used in the two cases are different. For example if the model contains a random variable z_1&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pyro&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z_1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;then the guide needs to have a matching sample statement&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;guide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pyro&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z_1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The module &lt;code class=&quot;highlighter-rouge&quot;&gt;pyro.optim&lt;/code&gt; provides support for optimization in Pyro. In particular it provides &lt;code class=&quot;highlighter-rouge&quot;&gt;PyroOptim&lt;/code&gt;, which is a wrap of PyTorch optimizers and provide management of optimizers for dynamically generated parameters. The &lt;code class=&quot;highlighter-rouge&quot;&gt;PyroOptim&lt;/code&gt; takes two arguments: a constructor for PyTorch optimizers &lt;code class=&quot;highlighter-rouge&quot;&gt;optim_constructor&lt;/code&gt; and a specification of the optimizer &lt;code class=&quot;highlighter-rouge&quot;&gt;arguments optim_args&lt;/code&gt;. There are two ways to specify the optimizer arguments in pyro. First is the simple way as shown in the example below in which the &lt;code class=&quot;highlighter-rouge&quot;&gt;optim_args&lt;/code&gt; is a fixed dictionary that specifies the arguments used to instantiate PyTorch optimizers for all the parameters:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyro.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;adam_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;betas&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adam_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The second approach require user to specify a callable function with a &lt;code class=&quot;highlighter-rouge&quot;&gt;module_name&lt;/code&gt; ,the Pyro name of the module containing the parameter) and the Pyro name of the parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;param_name&lt;/code&gt; signatures as shown in example below:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;callable_param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'my_special_parameter'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.010&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;lr&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;callable_param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once a model, guide and optimizer have been specified, we can then perform learning and inference which is an optimization problem of maximizing the evidence lower bound (ELBO). The ELBO, is a function of both &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;, defined as an expectation w.r.t. to samples from the guide:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{\rm ELBO} \equiv \mathbb{E}_{q_{\phi}({\bf z})} \left [
\log p_{\theta}({\bf x}, {\bf z}) - \log q_{\phi}({\bf z})
\right]&lt;/script&gt;

&lt;p&gt;The following example show how to construct an instance of SVI that will do optimization via the ELBO objective:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pyro.infer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Trace_ELBO&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;svi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVI&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;guide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Trace_ELBO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This  SVI object provides two methods, &lt;code class=&quot;highlighter-rouge&quot;&gt;step()&lt;/code&gt; which takes a single gradient step and returns an estimate of the loss (i.e. minus the ELBO)  and &lt;code class=&quot;highlighter-rouge&quot;&gt;evaluate_loss()&lt;/code&gt; which returns only an estimate of the loss without taking a gradient step.&lt;/p&gt;

&lt;p&gt;For a model with N observations, running the model and guide and constructing the ELBO involves evaluating log pdf’s whose complexity scales badly with N. This is a problem if we want to scale to large datasets. Luckily, the ELBO objective naturally supports subsampling provided that our model/guide have some conditional independence structure that we can take advantage of. For example, in the case that the observations are conditionally independent given the latents, the log likelihood term in the ELBO can be approximated with.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i=1}^N \log p({\bf x}_i | {\bf z}) \approx  \frac{N}{M}
\sum_{i\in{\mathcal{I}_M}} \log p({\bf x}_i | {\bf z})&lt;/script&gt;

&lt;p&gt;where $\mathcal{I}_M$ is a mini-batch of indices of size M with M&amp;lt;N.&lt;/p&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Stochastic Variational Inference (SVI)</title><link href="https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/10/stochastic_variational_bayes.html" rel="alternate" type="text/html" title="Stochastic Variational Inference (SVI)" /><published>2018-11-10T16:12:00+01:00</published><updated>2018-11-11T16:58:41+01:00</updated><id>https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/10/stochastic_variational_bayes</id><content type="html" xml:base="https://sambaiga.github.io/ml/deep%20learning/probability/2018/11/10/stochastic_variational_bayes.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;&quot;&gt;previous post&lt;/a&gt;  introduced the basic principle of Variational Inference (VI) as one of the approach used to approximate difficult probability distribution, derived the ELBO function and discussed about Mean Field Variational Inference (MFVI) and the Coordinate Ascent Variational Inference (CAVI) algorithms. This post introduce another  stochastic gradient based algorithm (SVI) used in practise to do VI under mean filed assumptions. It also present two important tricks re-parametrization trick and amortized inference that are useful when using SVI in solving problems.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-variational-inference-svi&quot;&gt;Stochastic Variational Inference (SVI)&lt;/h2&gt;
&lt;p&gt;Consider the graphical model of the observations &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; and latent variable &lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}=\{\theta, z\}&lt;/script&gt; in figure 1 where &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is the global variable and &lt;script type=&quot;math/tex&quot;&gt;z = \{z_1, \ldots z_n\}&lt;/script&gt;  is the local (per-data-point) variable such that:&lt;/p&gt;

&lt;figure id=&quot;figure-1&quot;&gt;&lt;a href=&quot;/assets/img/post//VI.png&quot;&gt;&lt;img src=&quot;/assets/img/post//VI.png&quot; alt=&quot;Graphical-model&quot; /&gt;&lt;/a&gt;&lt;figcaption&gt;Figure 1: Graphical-model [&lt;a href=&quot;/assets/img/post//VI.png&quot;&gt;PNG&lt;/a&gt;]&lt;/figcaption&gt;&lt;/figure&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{x},\mathbf{z}) = p(\theta|\alpha)\prod_{i=1}^N p(x_i|z_i, \theta)\cdot p(z_i|\alpha)&lt;/script&gt;

&lt;p&gt;Similarly the variational parameters are given by &lt;script type=&quot;math/tex&quot;&gt;\lambda = \{\gamma, \phi\}&lt;/script&gt; where the variational parameter &lt;script type=&quot;math/tex&quot;&gt;\gamma&lt;/script&gt; correspond to latent variable  and  &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; denote set of local variational parameters. The variational distribution &lt;script type=&quot;math/tex&quot;&gt;q(\mathbf{z}\mid \phi)&lt;/script&gt; is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(\mathbf{z}\mid \phi) = q(\theta|\gamma)\prod_{i=1}^N q(z_i|\phi_i, \alpha)&lt;/script&gt;

&lt;p&gt;which  also depend on hyper-parameter &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt;. The ELBO of this graphical model &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_{VI}(q) = \mathbb{E}_q[ \log p(\mathbf{x},\mathbf{z}, \alpha) -\log q(\mathbf{z}, \gamma)]&lt;/script&gt; has the following form:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{split}
\mathcal{L}_{VI}(q) &amp;= \mathbb{E}_q[ \log p(\theta|\alpha)- \log q(\theta|\gamma)] \\
&amp;+ \sum_{i=1}^{N}\mathbb{E}_q[\log p(z_i|\theta) 
+ \log p(x_i|z_i, \theta)-\log q(z_i|\phi_i)]
\end{split} %]]&gt;&lt;/script&gt;

&lt;p&gt;The equation above could be optimized by CAVI algorithm discussed in previous post which is expensive for large data sets. The CAVI algorithm scales with &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; as it require to optimize the local variational parameters for each data point before re-estimating the global variational parameters.&lt;/p&gt;

&lt;p&gt;Unlike CAI, SVI uses stochastic optimization to fit the global variational parameters by repeatedly sub-sample the data to form stochastic estimate of ELBO. In every iteration one randomly selects mini-batches of size &lt;script type=&quot;math/tex&quot;&gt;b_{sz}&lt;/script&gt;  to obtain a stochastic estimate of ELBO.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{split}
\mathcal{L}_{VI}(q) &amp;= \mathbb{E}_q[ \log p(\theta|\alpha)- \log q(\theta|\gamma)] \\
&amp;+ \frac{N}{b_{sz}}\sum_{s=1}^{b_{sz}}\mathbb{E}_q[\log p(z_{i_s}|\theta) + \log p(x_{i_s}|z_{i_s}, \theta)-\log q(z_{i_s}|\phi_{i_s})]
\end{split} %]]&gt;&lt;/script&gt;

&lt;p&gt;SVI algorithms follow noisy estimates of the gradient with a decreasing step size which is often  cheaper to compute than the true gradient. Following such noisy estimates allows SVI to escape  shallow local optima of complex objective functions.&lt;/p&gt;

&lt;h3 id=&quot;natural-gradient-for-svi&quot;&gt;Natural Gradient for SVI&lt;/h3&gt;

&lt;p&gt;To solve the optimization problem standard gradient-based methods such as SGD, Adam or Adagrad can be used. However, for SVI these gradient based methods cause slow convergence or converge to inferior local models. This is because, gradient based methods use the following update&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta^{t+1}=\theta^t + \alpha \frac{\partial \mathcal{L}_{VI}(q)}{\partial \theta}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial \mathcal{L}_{VI}(q)}{\partial \theta} =\frac{\partial \mathcal{L}_{VI}(q)}{\partial \theta_1}, \ldots \frac{\partial \mathcal{L}_{VI}(q)}{\partial \theta_k}&lt;/script&gt;

&lt;p&gt;is the the gradient vector which point in the direction where the function increases most quickly while the changes in the function are measured with respect to euclidean distance. As the result, if the euclidean distance between the variational parameter being optimized is not good measure of variation in objective function then gradient descent will move suboptimal through the parameter value.&lt;/p&gt;

&lt;p&gt;Consider the following  two set of gausian distributions &lt;script type=&quot;math/tex&quot;&gt;\{d_{(1)}=\mathcal{N}(-2, 3), d_{(2)}=\mathcal{N}(2, 3)\}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\{d_{(1)}=\mathcal{N}(-2, 1), d_{(2)}=\mathcal{N}(2, 1)\}&lt;/script&gt;.&lt;/p&gt;

&lt;figure id=&quot;figure-2&quot;&gt;&lt;a href=&quot;/assets/img/post//distribution.png&quot;&gt;&lt;img src=&quot;/assets/img/post//distribution.png&quot; alt=&quot;&amp;#39;PDF&amp;#39;&quot; /&gt;&lt;/a&gt;&lt;figcaption&gt;Figure 2: &amp;#39;PDF&amp;#39; [&lt;a href=&quot;/assets/img/post//distribution.png&quot;&gt;PNG&lt;/a&gt;]&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;The euclidean distance between the two distributions &lt;script type=&quot;math/tex&quot;&gt;d_{}=\sqrt{(\mu_1-\mu_2)^2+ (\sigma^2_1-\sigma^2_2)^2}=4&lt;/script&gt;. It clear that, considering only the euclidean distance the two images are the same. However, when we consider the shape of the distribution, the distance is different in the first and second image. In the first image, the KL-divergence should be lower as there is more overlap between between the two distribution unlike the second image where their support barely overlap. The reason for this difference is that probability distribution do not naturally fit in euclidean space rather it fit on a statistical manifold also called &lt;a href=&quot;https://en.wikipedia.org/wiki/Riemannian_manifold&quot;&gt;Riemannian manifold&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Statistical manifold give a natural way of measuring distances between distribution that euclidean distance use in SGD. A common Riemannian metric for statistical manifold is the &lt;a href=&quot;https://wiseodd.github.io/techblog/2018/03/11/fisher-information/&quot;&gt;fisher information matrix&lt;/a&gt; defined by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_{\lambda} = \mathbb{E}_{p(x;\lambda)}[\nabla \log p(x;\lambda) (\nabla \log p(x;\theta))^T ]&lt;/script&gt;

&lt;p&gt;It can be showed that the fisher information matrix &lt;script type=&quot;math/tex&quot;&gt;F_{\lambda}&lt;/script&gt; is  the second derivative of the KL divergence between two distributions.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F_{\theta} = \nabla^2_{\theta} KL(q(x;\lambda)||p(x;\theta))&lt;/script&gt;

&lt;p&gt;Thus for SVI, the standard gradients descent techniques can be replaced  with the natural gradient as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{\nabla_{q}} \mathcal{L}(q) = F^{-1} \nabla{q}\mathcal{L}_{VI}(q)&lt;/script&gt;

&lt;p&gt;The update procedure for natural gradient can be summarized as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Compute the loss &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_{VI}(q)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Compute the gradient of the loss &lt;script type=&quot;math/tex&quot;&gt;\nabla{q}\mathcal{L}_{VI}(q)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Compute the Fisher Information Matrix F.&lt;/li&gt;
  &lt;li&gt;Compute the natural gradient &lt;script type=&quot;math/tex&quot;&gt;\tilde{\nabla_{q}} \mathcal{L}_{VI}(q)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Update the parameter &lt;script type=&quot;math/tex&quot;&gt;q^{t+1} =q^t - \alpha \tilde{\nabla_{\theta}}\mathcal{L}_{VI}(q)&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Using natural gradient instead of standard gradients simplify SVI gradient update. However the same conditions for convergence as standard SDG have to be fulfilled. First, the mini-batch indices must be drawn uniformly at random size where the size &lt;script type=&quot;math/tex&quot;&gt;b_{sz}&lt;/script&gt; of the mini-batch must satisfies &lt;script type=&quot;math/tex&quot;&gt;1\leq b_{sz} \leq N&lt;/script&gt; The learning rate &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; needs to decrease with iterations &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; satisying the &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_approximation&quot;&gt;Robbins Monro conditions&lt;/a&gt; &lt;script type=&quot;math/tex&quot;&gt;\sum_{t=1}^{\infty} \alpha_t =\infty&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\sum_{t=1}^{\infty} \alpha_t^2 &lt;\infty %]]&gt;&lt;/script&gt; This guarantee that every point in the parameter space can be reached while the gradient noise decreases quickly enough to ensure convergence.&lt;/p&gt;

&lt;p&gt;The next section presents two important tricks namely re-parametrization trick and amortized inference that are useful when using SVI in solving problems.&lt;/p&gt;

&lt;h2 id=&quot;re-parametrization-trick&quot;&gt;Re-parametrization trick&lt;/h2&gt;

&lt;p&gt;Consider the graphical model presented in figure 1, where gradient based stochastic optimization is used to learn the variational parameter &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;. For example; for Gaussian distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{\phi}(z|x)=\mathcal{N}(\mu_{\phi}(x), \Sigma_{\phi}(x))&lt;/script&gt;

&lt;p&gt;to maximize the likelihood of the data, we need to back propagate the loss to the parameter &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; across the distribution of &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; or across sample &lt;script type=&quot;math/tex&quot;&gt;z\sim q_\phi(z \mid x)&lt;/script&gt; However, it is difficulty to back-propagate through random variable. To address this problem, the re-parametrization trick is used.First let consider the &lt;a href=&quot;https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician&quot;&gt;Law of the Unconscious Statistician (LOTUS)&lt;/a&gt;, used to calculate the expected value of a function &lt;script type=&quot;math/tex&quot;&gt;g(\epsilon)&lt;/script&gt; of a random variable &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt; when only the probability distribution &lt;script type=&quot;math/tex&quot;&gt;p(\epsilon)&lt;/script&gt; of &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt; is known. It state that:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;To compute the expectation of a measurable function &lt;script type=&quot;math/tex&quot;&gt;g(.)&lt;/script&gt; of a random variable &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;, we have to integrate &lt;script type=&quot;math/tex&quot;&gt;g(\epsilon)&lt;/script&gt; with respect to the distribution function of &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;, that is:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}(g(\epsilon)) = \int g(\epsilon)dF_{\epsilon}(\epsilon)&lt;/script&gt;

&lt;p&gt;In other words, to compute the expectation of &lt;script type=&quot;math/tex&quot;&gt;z =g(\epsilon)&lt;/script&gt; we only need to know &lt;script type=&quot;math/tex&quot;&gt;g(.)&lt;/script&gt; and the distribution of &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;. We do not need to explicitly know the distribution of &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. Thus the above equation can be expression in the convenient alternative notation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{\epsilon \sim p(\epsilon)}(g(\epsilon)) = \mathbb{E}_{z \sim p(z)} (z)&lt;/script&gt;

&lt;p&gt;Therefore the reparameteriztaion trick states that:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;A random variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; with distribution &lt;script type=&quot;math/tex&quot;&gt;q_{\phi}(z, \phi)&lt;/script&gt; which is independent to &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; can be expressed as transformation of random variable &lt;script type=&quot;math/tex&quot;&gt;\epsilon \sim p(\epsilon)&lt;/script&gt; that come from noise distribution such as uniform or gaussian such that &lt;script type=&quot;math/tex&quot;&gt;z = g(\phi, \epsilon)&lt;/script&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For instance for Gaussian variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; in the above example 
&lt;script type=&quot;math/tex&quot;&gt;z = \mu(\phi) + \sigma^2(\phi)\cdot \epsilon&lt;/script&gt;
where &lt;script type=&quot;math/tex&quot;&gt;\epsilon \sim \mathcal{N}(0, 1)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Since &lt;script type=&quot;math/tex&quot;&gt;p(\epsilon)&lt;/script&gt; is independent of the parameter of &lt;script type=&quot;math/tex&quot;&gt;q_{\phi}(z, \phi)&lt;/script&gt;, we can apply the change of variables in integral theory to compute any expectation over &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; or any expectation over  &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;. The SDG estimator can therefore be estimated by pulling the gradient into expectations and approximating it by samples from the noise 
distribution such that  for any measurable function &lt;script type=&quot;math/tex&quot;&gt;f_{\theta}(.)&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Delta_{\phi}\mathbb{E}_{z\sim p_{\phi}(z)} = \frac{1}{M}\sum_{i=1}^M \Delta f(g(\phi, \epsilon_i))&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\epsilon_i\sim p(\epsilon)&lt;/script&gt; , &lt;script type=&quot;math/tex&quot;&gt;f_{\theta}(.)&lt;/script&gt; must be differentiable w.r.t  its input &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;g(\phi, \epsilon_i)&lt;/script&gt; must exist and be differentiable with respect to &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;amortized-variational-inference&quot;&gt;Amortized Variational Inference&lt;/h2&gt;

&lt;p&gt;Consider the graphical model presented in figure 1 where ecah data point &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt; is governed by its latent variable &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; with variational parameter &lt;script type=&quot;math/tex&quot;&gt;phi_i&lt;/script&gt; such that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(\mathbf{z}\mid \phi) = q(\theta|\gamma)\prod_{i=1}^N q(z_i|\phi_i, \alpha)&lt;/script&gt;

&lt;p&gt;Using traditional SVI make it necessary to optimize &lt;script type=&quot;math/tex&quot;&gt;\phi_i&lt;/script&gt; for each data point &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;. As the results the number parameters to be optimized will grows with the number of observations &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. This is not ideal for larger datasets. Apart from that, it requires one to re-run the optimization procedure in case of new observation or when we have to perform inference. To address these problem amortized VI introduce a parametrized function that maps from observation space to the parameter of the approximate posterior distribution.&lt;/p&gt;

&lt;p&gt;Amortized VI try to learn from past inference/pre-computation so that future inferences run faster. Instead of approximating separate variables for each data point &lt;script type=&quot;math/tex&quot;&gt;x_i&lt;/script&gt;, amortized VI assume that the local variational parameter &lt;script type=&quot;math/tex&quot;&gt;\phi&lt;/script&gt; can be predicted by a parametrized function &lt;script type=&quot;math/tex&quot;&gt;f_{\phi}(.)&lt;/script&gt; of data whose parameters are shared across all data points. Thus instead of introducing local variational parameter, we learn a single parametric function and work with a variational distribution that has the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(\mathbf{z}\mid \phi) = q(\theta|\gamma)\prod_{i=1}^N q(z_i|f_{\phi}(.))&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;f_{\phi}(.)&lt;/script&gt; is the deep neural net function of &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Deep neural network used in this context are called &lt;a href=&quot;&quot;&gt;inference networks&lt;/a&gt;. Therefore amortized inference with inference networks combines probabilistic modelling with representation power of deep learning. Using amortized VI instead of traditional VI, has two important advantages. First the number of variational parameters remain constant with respect to the data size. We only need to specify the parameter of the neural networks which is independent to the number of observations. Second, for new observation or during inference all we need to do is to call the inference network. As the result, we can invest time upfront optimizing the inference network and during inference we use the trained network for fast inference.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.05597&quot;&gt;[Cheng Zhang,(2017)]&lt;/a&gt;:
Advances in Variational Inference.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.05735&quot;&gt;[Daniel Ritchie,(2016)]&lt;/a&gt;:Deep Amortized Inference for Probabilistic Programs.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.05735&quot;&gt;[Andrew Miller,(2016)]&lt;/a&gt;:Natural Gradients and Stochastic Variational Inference.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.shakirm.com/papers/VITutorial.pdf&quot;&gt;Shakir Mohamed&lt;/a&gt;:Variational Inference  for Machine Learning.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://emtiyaz.github.io/teaching/ds3_2018/ds3.html&quot;&gt;DS3 workshop&lt;/a&gt;:Approximate Bayesian Inference: Old and New.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/philschulz/VITutorial&quot;&gt;Variational Inference and Deep Generative Models&lt;/a&gt;:Variational Inference for NLP audiences&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Bayesian Inference</title><link href="https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/28/bayesian_inference.html" rel="alternate" type="text/html" title="Bayesian Inference" /><published>2018-06-28T17:12:00+02:00</published><updated>2018-11-11T16:58:41+01:00</updated><id>https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/28/bayesian_inference</id><content type="html" xml:base="https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/28/bayesian_inference.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Bayesian method offer a different paradigm for doing statistical analysis. It is practical method for making inferences from data using probability models. Unlike other statistical approach, bayesian models are easy to interpret and incorporate uncertainty. In bayesian method  we start with a belief which is also called a &lt;strong&gt;prior&lt;/strong&gt;. We then update our belief after observing some data. The outcome is called a &lt;strong&gt;posterior&lt;/strong&gt;. The process repeats as we keep on observing more data where the old &lt;em&gt;posterior&lt;/em&gt; becomes a new &lt;em&gt;prior&lt;/em&gt;. The  process employs the Bayes rule.&lt;/p&gt;

&lt;p&gt;Consider the Bayesian theorem, which allows us to use some knowledge or belief that we already have. Given data point &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D} = \{x \in \mathbb{R}^{N\times d}, y \in \mathbb{R}^{N\times c}\}&lt;/script&gt;. The Bayesian  approach  treat the latent variable or parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; as random variable with some prior distribution &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt;. This is the probability of parameters &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; before hand.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z | \mathcal{D}  ) = \frac{p(\mathcal{D} | z )\cdot p(z)}{p(\mathcal{D})}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathcal{D}) = \int p(\mathcal{D} |z )\cdot p(z) dz&lt;/script&gt;

&lt;p&gt;From the bayesian theorem above,  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; is the hypothesis about the world, and &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; is the data or evidence. The probability &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D} \mid z)&lt;/script&gt; is called  &lt;strong&gt;likeli-hood&lt;/strong&gt;; the probability of data given the latent variable and &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D})&lt;/script&gt; is the &lt;strong&gt;marginal-likelihood&lt;/strong&gt; and &lt;script type=&quot;math/tex&quot;&gt;p(z \mid \mathcal{D}  )&lt;/script&gt; is the &lt;strong&gt;posterior&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;bayesian-inference&quot;&gt;Bayesian Inference&lt;/h3&gt;

&lt;p&gt;Given data set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; and latent variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; that relate &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; such that:
&lt;script type=&quot;math/tex&quot;&gt;y = f_{z}(x:z)&lt;/script&gt;
The first step in bayesian inference is to identify the parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; and express our lack of knowledge  about this parameter in term of probability distribution &lt;script type=&quot;math/tex&quot;&gt;p(z)&lt;/script&gt;. This is the prior knowledge about the parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. After that we express a &lt;em&gt;likelihood&lt;/em&gt;  &lt;script type=&quot;math/tex&quot;&gt;p(\mathcal{D} \mid z)&lt;/script&gt; which tell us how the data &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt; interact with  parameter &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. Together the prior and the likelihood make our model (generative model). It tell us how we can simulate from our data.&lt;/p&gt;

&lt;p&gt;In &lt;strong&gt;training&lt;/strong&gt; stage we apply Bayesian theorem to get posterior distribution:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z|\mathcal{D}) = \frac{p(\mathcal{D}|, z)}{p(\mathcal{D})}&lt;/script&gt;

&lt;p&gt;In testing stage we find &lt;strong&gt;predictive-distribution&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\hat{y}| x, \mathcal{D}) = \int p(\hat{y} | x, z)\cdot p(z | x, y) dz&lt;/script&gt;

&lt;p&gt;Theoretically this is how bayesian inference work, however the big challenge is how to compute the posterior distribution. The integral &lt;script type=&quot;math/tex&quot;&gt;\int p(\mathcal{D} \mid z )\cdot p(z) dz&lt;/script&gt; is usually intractable. Therefore we need to approximate this integral. There several approach used for approximation.&lt;/p&gt;

&lt;p&gt;The first and simple approach is to use &lt;em&gt;analytical integration&lt;/em&gt; which is only applicable with the use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Conjugate_prior&quot;&gt;conjugate prior&lt;/a&gt; and thus possible only for very simple cases. However the approach does not scale well. Alternatively &lt;em&gt;&lt;a href=&quot;https://metacademy.org/graphs/concepts/laplace_approximation&quot;&gt;Gaussian (Laplace) approximation&lt;/a&gt;&lt;/em&gt; can be applied where the posterior is  approximated  with Gaussian. This works well when there are lot of data. &lt;a href=&quot;https://metacademy.org/graphs/concepts/markov_chain_monte_carlo&quot;&gt;Markov Chain Monte Carlo (MCMC)&lt;/a&gt; are among other popular techniques used for approximating the integral. The method is applicable to wide variety of problems however is very slow. The popular and recently widely used approach for approximating prior in bayesian method is &lt;em&gt;Variational Inference&lt;/em&gt;. This approach convert the integral into optimization problem and thus Work faster than MCMC.&lt;/p&gt;

&lt;p&gt;Before we dive into varitiaonl infrence let us revisit one example of bayesian inference in regression problem. Given data point &lt;script type=&quot;math/tex&quot;&gt;X = \{x_1,\ldots x_N \}&lt;/script&gt; and corresponding target &lt;script type=&quot;math/tex&quot;&gt;Y = \{y_1,\ldots y_N \}&lt;/script&gt;. Linear regression assume that data is generated from the following model:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y= f_{\theta}(x: \theta) + \in&lt;/script&gt;
 where &lt;script type=&quot;math/tex&quot;&gt;\in&lt;/script&gt; is the noise due to measurement and 
&lt;script type=&quot;math/tex&quot;&gt;f_{\theta}(X: \theta)&lt;/script&gt; is the hypothesis function given;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{\theta}(X: \theta) = b + \sum_{i=1}^N w_i \phi (x_i) = \theta^T\cdot \phi(X)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\phi(X)&lt;/script&gt; is the basis function and &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is the model parameters such that 
&lt;script type=&quot;math/tex&quot;&gt;\theta_{0} =b&lt;/script&gt;  and &lt;script type=&quot;math/tex&quot;&gt;\phi_0=1&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The  output of this model is the single point estimate for the best model parameter. The Bayesian modelling approach to this problem offer a systematic framework for learning distribution over values of the parameters and not a single estimate. The bayesian linear regression model &lt;script type=&quot;math/tex&quot;&gt;y= f_{\theta}(x: \theta) + \in&lt;/script&gt; as a Gaussian  distribution such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y|x, \theta) = \mathcal{N}(y|f_{\theta}(x: \theta), \beta^{-1})&lt;/script&gt;

&lt;p&gt;Assuming the data point are drawn independently and identically distributed the likelihood is expressed as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(Y| X, \theta) = \prod_{i=1}^N \mathcal{N}(y_i|f_{\theta}(x_i: \theta_i), \beta^{-1})&lt;/script&gt;

&lt;p&gt;Let choose a prior that is conjugate to the likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta|X) = \mathcal{N}(\theta|0, \alpha^{-1})&lt;/script&gt;

&lt;p&gt;Thus the posterior is given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta|Y, X) \propto \mathcal{N}(\theta|0, \alpha^{-1})\cdot \prod_{i=1}^N \mathcal{N}(y_i|f_{\theta}(x_i: \theta_i), \beta^{-1})&lt;/script&gt;

&lt;h2 id=&quot;variational-inference-vi&quot;&gt;Variational Inference (VI)&lt;/h2&gt;

&lt;p&gt;In the previous section we show that inference in probabilist model is often intractable and introduced several approach used to approximate the inference. Variational Inference (VI) is one of the approach used to approximate difficult probability distribution by turning the calculation about model into optimization.&lt;/p&gt;

&lt;p&gt;Consider a probabilistic model which is joint distribution &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; of the latent variable  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; observed variables &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. To draw inference on the latent variable &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; we compute the posterior&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(z|x) = \frac{p(x,z)}{p(x)} = \frac{p(x|z)\cdot p(z)}{p(x)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x)=\int p(x|z)\cdot p(z) dz&lt;/script&gt;

&lt;p&gt;To approximate &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; we first choose an approximating family of distribution &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; over latent variable  &lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt;. Then we find set of parameters that makes &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; close to posterior distribution &lt;script type=&quot;math/tex&quot;&gt;p(z\mid {\bf x})&lt;/script&gt;. Thus VI approximate &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; with new distribution &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; is close to &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt;. To achieve this we minimize KL divergence between &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt; such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z) = \arg \min D_{KL}(q(z)||p(z|x))&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(q(z)||p(z|x)) = \int q(z)\log \frac{q(z)}{p(z|x)}&lt;/script&gt;

&lt;p&gt;It clear that we can not minimize KL divergence since it is directly depend on posterior &lt;script type=&quot;math/tex&quot;&gt;p(z\mid x)&lt;/script&gt;. However we can minimize a function that is equal to KL divergence plus constant. This function is called &lt;strong&gt;Evidence Lower Bound&lt;/strong&gt;(ELBO) &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}_{VI}(q)&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;evidence-lower-bound-elbo&quot;&gt;Evidence Lower Bound (ELBO)&lt;/h3&gt;

&lt;p&gt;To derive the ELBO we first consider the &lt;a href=&quot;https://en.wikipedia.org/wiki/Jensen%27s_inequality&quot;&gt;Jensen’s inequality&lt;/a&gt; which relates the value of a convex function of an integral to the integral of the convex function such that &lt;script type=&quot;math/tex&quot;&gt;f(\mathbb{E}[x]) \geq \mathbb{E}[f(x)]&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;f(.)&lt;/script&gt; is the concave function. Since logarithmic are strictly concave function it is clear that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log \int p(x)g(x) dx \geq \int p(x)\log g(x)&lt;/script&gt;

&lt;p&gt;Let us consider a log of marginal evidence.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
\log p(x) &amp; = \log \int_z p(x,z) dz\\
          &amp; =\log \int_z p(x,z)\cdot \frac{q(z)}{q(z)} dz \\
          &amp; =\log \int_z q(z)\frac{p(x,z)}{q(z)} dz\\
          &amp; =\log \left(\mathbb{E}_q[\frac{p(x,z)}{q(z)}] \right)\\
          &amp;\geq \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The final line is the ELBO which is the lower bound for the evidence. Thus the evidence lower bound for probability model &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; and approximation &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; to the posterior is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{VI}(q) = \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]&lt;/script&gt;

&lt;p&gt;We can now show that KL divergence to the posterior is equal to the negative ELBO plus constant.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
D_{KL}(q(z)||p(z|x)) &amp;= \int q(z)\log \frac{q(z)}{p(z|x)}\\
                     &amp;= \mathbb{E}_q[\log q(z)] - \mathbb{E}_q[\log p(x,z)] + \mathbb{E}_q[\log p(x)]\\
                     &amp;=-\left(\mathbb{E}_q[\log p(x,z)] - \mathbb{E}_q[\log q(z)] \right) +\log p(x)\\
                     &amp;= -\mathcal{L}_{VI}(q) +\log p(x)\\
\mathcal{L}_{VI}(q) &amp;=\log p(x) + D_{KL}(q(z)||p(z|x))
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;From the equation above it clear that minimizing the KL divergence is equivalent to maximizing the ELBO. Recall that we want to find &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; such that KL divergence is small, the variational objective function becomes&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z) = \arg \min D_{KL}(q(z)||p(z|x)) = \arg \max \mathcal{L}_{VI}(q)&lt;/script&gt;

&lt;h3 id=&quot;mean-field-variational-inference&quot;&gt;Mean Field Variational Inference&lt;/h3&gt;

&lt;p&gt;One of the important question on VI, is how to construct the family of variational distributions from which we want to draw &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; from. The simplest family is where each latent parameter &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; has its own
independent distribution. This means that we can easily factorize the variational distributions into groups:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q(z_1, \ldots, z_m) = \prod_{i=1}^m q(z_i)&lt;/script&gt;

&lt;p&gt;This family of distribuion are known as Mean-Field Variational Family that make use of &lt;a href=&quot;https://en.wikipedia.org/wiki/Mean_field_theory&quot;&gt;mean field theory&lt;/a&gt;. Inference using this factorization is known as Mean-Field Variational Inference (MFVI).&lt;/p&gt;

&lt;p&gt;It possible to further parameterize the approximating distributions &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt; with variational parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; such that the approximating distribution become &lt;script type=&quot;math/tex&quot;&gt;q(z_i ; \lambda_i)&lt;/script&gt;. For example if we set our family of approximating distributions as a set of
independent gauasian distributions &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mu_i, \sigma^2_i)&lt;/script&gt; and parameterize this distributions with the mean and variance where &lt;script type=&quot;math/tex&quot;&gt;\lambda_i = (\mu_i, \sigma^2_i)&lt;/script&gt; is the set of variational parameters.&lt;/p&gt;

&lt;p&gt;The common algorithms used in practise to do VI under mean filed assumptions are coordinate ascent optimization (CAVI) and stochastic gradient based method.&lt;/p&gt;

&lt;h3 id=&quot;coordinate-ascent-variational-inference-cavi&quot;&gt;Coordinate Ascent Variational Inference (CAVI)&lt;/h3&gt;

&lt;p&gt;The CAVI algorithm derive variational updates by hand and perform coordinate ascent (iteratively updating each latent variable &lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; ) on the latent until convergence of the ELBO. A common procedure to conduct CAVI is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choose variational distributions &lt;script type=&quot;math/tex&quot;&gt;q(z)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Compute ELBO;&lt;/li&gt;
  &lt;li&gt;Optimize individual &lt;script type=&quot;math/tex&quot;&gt;q(z_i)&lt;/script&gt; ’s by taking the gradient for each latent variable;&lt;/li&gt;
  &lt;li&gt;Repeat until ELBO converges.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The coordinate ascent update for a latent variable can be derived by maximizing the ELBO function above. First, recall ELBO&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{VI}(q) = \mathbb{E}_q[ \log p(x,z)] - \mathbb{E}_q[\log q(z)]&lt;/script&gt;

&lt;p&gt;Using chain rule we can decomopse the joint  &lt;script type=&quot;math/tex&quot;&gt;p(x,z)&lt;/script&gt; as;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x_{1:n}, z_{1:m}) = p(x_{1:n}) \prod_{i=1}^m p(z_i|z_{1:(i-1)}, x_{1:n})&lt;/script&gt;

&lt;p&gt;Using mean field approximation, we can decompose the entropy term of the ELBO as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_q[\log q(z)] = \sum_{i=1}^m \mathbb{E}_q[\log q(z_i)]&lt;/script&gt;

&lt;p&gt;Under the above assumption the ELBO become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{ELBO}(q) = \log p(x_{1:n}) + \sum_{i=1}^m \mathbb{E}_q[\log p(z_i|z_{1:(i-1)}, x_{1:n}) ] - \mathbb{E}_q[\log q(z_i)&lt;/script&gt;

&lt;p&gt;To find this &lt;script type=&quot;math/tex&quot;&gt;\arg \max_{q(z_i)} \mathcal{L}_{ELBO}(q)&lt;/script&gt; we take derivative of ELBO with respect to &lt;script type=&quot;math/tex&quot;&gt;q(z_i)&lt;/script&gt; using Lagrange multipliers and set the derivative to zero. It can be shown that the coordinate ascent update rule is equal to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^*(z_i) \propto \{  \mathbb{E}_{q-i}[\log q(z_i,z_{\neg},x)]\}&lt;/script&gt;

&lt;p&gt;where the notation &lt;script type=&quot;math/tex&quot;&gt;\neg&lt;/script&gt; denotes all indices other than the &lt;script type=&quot;math/tex&quot;&gt;i^{th}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Despite being very fast  method for some models  only  work with  conditionally conjugate models.&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.tamarabroderick.com/tutorial_2018_icml.html&quot;&gt;ICML 2018 tutorial&lt;/a&gt;:Variational Bayes and Beyond: Bayesian Inference for Big Data.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.shakirm.com/papers/VITutorial.pdf&quot;&gt;Shakir Mohamed&lt;/a&gt;:Variational Inference  for Machine Learning.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://emtiyaz.github.io/teaching/ds3_2018/ds3.html&quot;&gt;DS3 workshop&lt;/a&gt;:Approximate Bayesian Inference: Old and New.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/philschulz/VITutorial&quot;&gt;Variational Inference and Deep Generative Models&lt;/a&gt;:Variational Inference for NLP audiences&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Basics of Probability and Information Theory</title><link href="https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/08/intro_probability_information_theory.html" rel="alternate" type="text/html" title="Basics of Probability and Information Theory" /><published>2018-06-08T17:12:00+02:00</published><updated>2018-11-11T16:58:41+01:00</updated><id>https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/08/intro_probability_information_theory</id><content type="html" xml:base="https://sambaiga.github.io/ml/deep%20learning/probability/2018/06/08/intro_probability_information_theory.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Probability and Information theory are important field that has made significant contribution to deep learning and AI. Probability theory allows us to make &lt;em&gt;uncertain statements&lt;/em&gt; and to &lt;em&gt;reason&lt;/em&gt; in the presence of &lt;em&gt;uncertainty&lt;/em&gt; where information theory enables us to &lt;em&gt;quantify&lt;/em&gt; the amount of &lt;em&gt;uncertainty&lt;/em&gt; in a probability distribution.&lt;/p&gt;

&lt;h2 id=&quot;1-probability-theory&quot;&gt;1. Probability Theory&lt;/h2&gt;

&lt;p&gt;Probability is a mathematical framework for representing uncertainty. It is very applicable in Machine learning and Artificial Intelligence as it allows to make &lt;em&gt;uncertain statements&lt;/em&gt; and  &lt;em&gt;reason&lt;/em&gt; in the presence of &lt;em&gt;uncertainty&lt;/em&gt;. Probability theory allow us to design ML algorithms that take into consideration  of &lt;em&gt;uncertain&lt;/em&gt; and sometimes &lt;em&gt;stochastic&lt;/em&gt;  quantities. It further tell us tell us how ML systems should &lt;em&gt;reason&lt;/em&gt; in the presence of uncertainty. This  is necessary because most things in the world  are uncertain, and thus  ML systems should reason using probabilistic rules. Probability theory can also be used to analyse the behaviour of  ML algorithms probabilistically. Consider evaluating ML classification algorithm using  accuracy metric which is  the probability that the model will give a correct prediction  given an example.&lt;/p&gt;

&lt;h3 id=&quot;12-random-experiment-sample-space-and-random-variable&quot;&gt;1.2 Random Experiment, Sample Space and Random Variable&lt;/h3&gt;
&lt;p&gt;Random experiment is the physical situation whose outcome cannot be predicted until it is observed. It is the process of observing event having uncertain outcome. When we repeat random experiment several times we call each of experiment a &lt;em&gt;trial&lt;/em&gt; The set of all possible outcomes of random experiment is know as &lt;em&gt;*sample space&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;. Consider observing the number of goals in the soccer match as a random process. The sample space is the possible number of goals &lt;script type=&quot;math/tex&quot;&gt;S = \{0,1,\ldots n\}&lt;/script&gt;. For coin tossing experiment the sample space is &lt;script type=&quot;math/tex&quot;&gt;S = \{\text{Head, Tail}\}&lt;/script&gt; and for handwritten digit recognition experiment the sample space is &lt;script type=&quot;math/tex&quot;&gt;S = \{0,1,\ldots 9\}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;A measurable function &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; which maps every member of the sample space &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; to a real-number is called &lt;strong&gt;random variable&lt;/strong&gt;. Random variables can be continuous or discrete. Discrete random variable take only countable number of distinct values for  example populations, movie ratings and number of votes. On the other hand continuous random variable take infinite number of possible values. Things like temperature, speed, time etc are all modelled as continuous variables.&lt;/p&gt;

&lt;h3 id=&quot;13-probability-and-probability-distribution&quot;&gt;1.3 Probability and Probability distribution&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Probability&lt;/strong&gt; is a measure of the likelihood that an event will occur in a random experiment. It is quantified as number between 0 and 1. The mathematical function that maps all possible outcome of a random experiment with its associated probability it is called &lt;strong&gt;probability distribution&lt;/strong&gt;. It describe how likely a random variable or set of random variable is to take on each of its possible state. The probability distribution for discrete random variable is called probability mass function (PMF) which measures the probability &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; takes on the value &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, denoted denoted as &lt;script type=&quot;math/tex&quot;&gt;P(X=x)&lt;/script&gt;.
To be PMF on random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;  a function &lt;script type=&quot;math/tex&quot;&gt;P(X)&lt;/script&gt; must satisfy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Domain of &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; equal to all possible states of &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall x \in X, 0\leq P(X=x) \leq 1&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{x \in X} P(x) =1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Popular and useful PMF includes poison, binomial, bernouli, and uniform. Let consider a poison  distribution defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X=x) = \frac{\lambda ^x e^{ -\lambda}}{x!}&lt;/script&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\lambda &gt;0&lt;/script&gt; is called a parameter of the distribution, and it controls the distribution’s shape. By increasing &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; , we add more probability to larger values, and conversely by decreasing &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;  we add more probability to smaller values as shown in figure below.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/pmf.png&quot; title=&quot;PMF of a Poisson random variable&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;PMF of a Poisson random variable
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Instead of a PMF, a continuous random variable has a probability density function (pdf) denoted as &lt;script type=&quot;math/tex&quot;&gt;f_X(x)&lt;/script&gt;. An example of continuous random variable is a random variable with exponential density.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_X(x\mid \lambda) = \lambda ^x e^{ -\lambda} \text{,  } x \geq 0&lt;/script&gt;

&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/pdf.png&quot; title=&quot;pdf of a exponential random variable&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;pdf of a exponential random variable
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;To be a probability density function &lt;script type=&quot;math/tex&quot;&gt;p(x)&lt;/script&gt; must satisfy&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The domain of &lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; must be the set of all possible state&lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall x \in X, f_X(x) \geq 0&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{x \in X} f_X(x)dx =1&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The pdf does not give the probability of a specific state directly. The probability that &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is between two point &lt;script type=&quot;math/tex&quot;&gt;a, b&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\int_{a}^b f_X(x)dx&lt;/script&gt;

&lt;p&gt;The probability of intersection of two or more random variables is called &lt;em&gt;joint probability&lt;/em&gt; denoted  as &lt;script type=&quot;math/tex&quot;&gt;P(X, Y)&lt;/script&gt;
Suppose we have two random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and we know the joint PMF or pdf distribution between these variable. The PMF or pdf  corresponding to a single variable is called &lt;em&gt;marginal probability distribution&lt;/em&gt; defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x) = \sum_{y\in Y} P(x, y)&lt;/script&gt;

&lt;p&gt;for discrete random variable and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x) = \int p(x)dy&lt;/script&gt;

&lt;p&gt;Marginalization allows us to get the distribution of variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; ignoring variable &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; from the joint distribution &lt;script type=&quot;math/tex&quot;&gt;P(X,Y)&lt;/script&gt;. The probability that some event will occur given we know other events is called condition probability denoted as &lt;script type=&quot;math/tex&quot;&gt;P(X\mid Y)&lt;/script&gt;. The  marginal, joint and conditional probability are linked by the following rule&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X|Y) = \frac{P(X, Y)}{P(Y)}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Independence, Conditional Independence and Chain Rule&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Two random variables are said to be independent of each other if the probability that one random variables occur in no way affect the probability of the other random variable occurring. &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are said to be independent if &lt;script type=&quot;math/tex&quot;&gt;P(X,Y) = P(X)\cdot P(Y)&lt;/script&gt;
On the other hand two random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are conditionally independent given an event &lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;P(Z)&gt;0&lt;/script&gt; if&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(X,Y\mid Z) = P(X\mid Y)\cdot P(Y\mid Z)&lt;/script&gt;
The good example of conditional independence can be found on this &lt;a href=&quot;&quot;&gt;link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Any joint probability distribution over many random variables may be decomposed into conditional distributions using &lt;em&gt;chain rule&lt;/em&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(X_1,X_2, \ldots, X_n ) = P(X_1)\prod_{i=2}^n P(X_i\mid X_i, \ldots X_{i-1})&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Expectation, Variance and Covariance&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Expected value of some function &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt; with respect to a probability distribution &lt;script type=&quot;math/tex&quot;&gt;P(X)&lt;/script&gt; is the average or mean value that &lt;script type=&quot;math/tex&quot;&gt;f(x)&lt;/script&gt; takes on when &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is drawn from &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{x\sim P}[f(x)] = \sum P(x).f(x)&lt;/script&gt;

&lt;p&gt;for discrete random variable and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{x\sim P}[f(x)] = \int P(x).f(x)dx&lt;/script&gt;

&lt;p&gt;Expectation are linear such that 
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x\sim P}[\alpha \cdot f(x) + \beta \cdot g(x)] = \alpha \mathbb{E}_{x\sim P}[f(x)] + \beta \mathbb{E}_{x\sim P}[g(x)]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Variance is a measure of how much the value of a function of random variable &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; vary as we sample different value of &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; from its probability distribution.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(f(x)) =\mathbb{E}([f(x)-\mathbb{E}[f(x)]^2])&lt;/script&gt;

&lt;p&gt;The square root of the variance is know as standard deviation. On the other hand the covarince give some sense of how much two value are linearly related to each other as well as the scale of these value.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cov(f(x), g(y)) = \mathbb{E}[(f(x)- \mathbb{E}[f(x)])(g(y)- \mathbb{E}[g(y)])]&lt;/script&gt;

&lt;h3 id=&quot;2-information-theory&quot;&gt;2. Information theory&lt;/h3&gt;
&lt;p&gt;Information theory deals with quantification of how much information is present in a signal. In context of machine learning, information theory we apply information theory to: &lt;em&gt;characterize probability distributions&lt;/em&gt; and &lt;em&gt;quantify similarities between probability distributions&lt;/em&gt;. The following are the key information concepts and their application to machine learning.&lt;/p&gt;

&lt;h3 id=&quot;21-entropy-cross-entropy-and-mutual-information&quot;&gt;2.1 Entropy, Cross Entropy and Mutual information&lt;/h3&gt;

&lt;p&gt;Entropy give measure of uncertainty in a random experiment. It help us  quantify the amount of uncertainty in an entire probability distribution. The entropy of a probability distribution is the expected amount of information in an event drawn from that distribution defined as.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(X) = -\mathbb{E}_{x \sim P}[\log P(x)] = -\sum_{i=1}^n P(x_i)l\log P(x_i)&lt;/script&gt;

&lt;p&gt;Entropy is widely used in model selection based on principle of maximum entropy. On the other hand, cross entropy is used to compare two probability distribution. It tell how similar two distribution are. The cross entropy between two probability distribution &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; defined over same set of outcome is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q)= -\sum P(x)\log Q(x)&lt;/script&gt;

&lt;p&gt;Cross entropy loss function is widely used in machine learning for classification problem.&lt;/p&gt;

&lt;p&gt;The mutual information over two random variables help us gain insight about the information that one random variable carries about the other.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
I(X, Y) &amp;= \sum P(x, y)\log \frac{P(x,y)}{P(x).P(y)}\\
        &amp;=H(X)- H(X\mid Y) = H(Y) - H(Y\mid X)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;From above equation the mutual information  give insight about how far &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; from being independent from each other. Mutual information can be used in feature selection instead of correlation as it capture both linear and non linear dependency.&lt;/p&gt;

&lt;h3 id=&quot;22-kullback-leibler-divergence&quot;&gt;2.2 Kullback-leibler Divergence&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kullback-leibler Divergence&lt;/strong&gt; measure how one probability distribution diverge from the other. Given two probability distribution &lt;script type=&quot;math/tex&quot;&gt;P(x)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q(X)&lt;/script&gt; where the former is the modelled/estimated distribution and the later is the actual/expected distribution. The &lt;strong&gt;KL&lt;/strong&gt; divergence is defined as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
D_{KL}(P||Q) &amp; = \mathbb{E}_{x \sim P} [\log \frac{P(x)}{Q(x)}]\\
             &amp; = \mathbb{E}_{x \sim P}[\log P(x)] - \mathbb{E}_{x \sim P}[\log Q(x)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;For discrete random distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(P||Q) = \sum_{i} P(x_i)\log \frac{P(x_i)}{Q(x_i)}&lt;/script&gt;

&lt;p&gt;And for continuous random variable&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{KL}(p||q) = \int_{x} p(x) \log \frac{p(x)}{q(x)}&lt;/script&gt;

&lt;p&gt;KL divergence between &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; tells how much information we lose when trying to approximate data given by &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt;. It is non-negative &lt;script type=&quot;math/tex&quot;&gt;D_{KL}(P\mid \mid Q) \geq 0&lt;/script&gt; and  &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; are the same (distribution discrete) or equal almost anywhere in the case of continuous distribution. Apart from that KL divergence is not symmetric &lt;script type=&quot;math/tex&quot;&gt;D_{KL}(P\mid \mid Q) \neq D_{KL}(P\mid \mid Q)&lt;/script&gt; because of this it is not a true distance measure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relation between KL divergence and Cross Entropy&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
D_{KL}(P||Q) &amp; = \mathbb{E}_{x \sim P} [\log \frac{P(x)}{Q(x)}]\\
             &amp; = \mathbb{E}_{x \sim P}[\log P(x)] - \mathbb{E}_{x \sim P}[\log Q(x)]\\
             &amp; = H(P) - H(P, Q)\\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim P}[\log P(x)] = H(P)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim P}[\log Q(x)] = H(P, Q)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H(P,Q) = H(P) - D_{KL}(P||Q)&lt;/script&gt;

&lt;p&gt;This implies that minimizing cross entropy with respect to &lt;script type=&quot;math/tex&quot;&gt;Q&lt;/script&gt; is equivalent to minimizing the KL divergence.&lt;/p&gt;

&lt;p&gt;KL divergence is used in unsupervised machine learning technique like variational auto-encoder. The KL divergence is also used  as objective function in variational bayesian method to find optimal value for approximating distribution.&lt;/p&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Mixture Density Newtorks</title><link href="https://sambaiga.github.io/ml/2018/01/03/mdn.html" rel="alternate" type="text/html" title="Mixture Density Newtorks" /><published>2018-01-03T16:12:00+01:00</published><updated>2018-11-11T16:58:41+01:00</updated><id>https://sambaiga.github.io/ml/2018/01/03/mdn</id><content type="html" xml:base="https://sambaiga.github.io/ml/2018/01/03/mdn.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Deep Learning models are widely used in prediction problem which involve learning associate mapping from set of inputs variables &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}=\{x_1, \ldots, x_d\}&lt;/script&gt; to a set of output variables &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}=\{y_1, \ldots,y_c\}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is the size of input features and &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; is the dimension of the output feature or target. In this case usually the network is trained using minimization of sum of squares errors or cross entropy error function over a set of training data &lt;script type=&quot;math/tex&quot;&gt;\{\mathbf{x}_{1:N},\mathbf{y}_{1:N}\}&lt;/script&gt; of the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L} = (\mathbf{y}-\hat\mathbf{y})^2  \text{  where  } \hat\mathbf{y}_{1:c}=f(\mathbf{x}_{1:d}, \mathbf{w, b})&lt;/script&gt;

&lt;p&gt;With this approach it is explicity assumed that there is a deterministic &lt;script type=&quot;math/tex&quot;&gt;1-to-1&lt;/script&gt; mapping between a given input variables &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}=\{x_1, \ldots, x_d\}&lt;/script&gt; and target variable  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}=\{y_1, \ldots,y_c\}&lt;/script&gt; without any uncertainity. As the result the output of the network trained by this approach approximates the conditional mean of the output in the training data conditioned on the input vector. For classification problem with well chosed target coding scheme these averages represents the posterior probability of class membership and thus can be regarded as optimal. For problem involving the prediction of continous variable especiall when the mapping to learned is multi-valued, the conditional averages is not usually a good description of data and doesnt have power to modal distribution of output with complex. One way to solve this problem is to model the complete conditional probability density instead, and this is the approach used by Mixture Density Networks (MDN).&lt;/p&gt;

&lt;h2 id=&quot;mixture-density-network&quot;&gt;Mixture Density Network&lt;/h2&gt;
&lt;p&gt;A MDN as proposed by Bishop, is a flexible framework for modelling an arbitray conditional probability distribution &lt;script type=&quot;math/tex&quot;&gt;p(\mathbf{y}|\mathbf{x})&lt;/script&gt;  as a mixture of distributions. It combines mixture model with DNN in which a DNN is used to parametrize a mixture model consisting of some predefined distributions. Considering gausian distribution, DNN  is used to map a set of input features &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}_{1:d}&lt;/script&gt; to the parameters of a GMM i.e mixture weights &lt;script type=&quot;math/tex&quot;&gt;\pi_k(\mathbf{x})&lt;/script&gt;, mean &lt;script type=&quot;math/tex&quot;&gt;\mu _k(\mathbf{x})&lt;/script&gt; and the covariance matrices &lt;script type=&quot;math/tex&quot;&gt;\sigma_k^2(\mathbf{x})&lt;/script&gt; which inturn gives a full probability density function of an output feature &lt;script type=&quot;math/tex&quot;&gt;\mathbf{y}&lt;/script&gt; conditioned on the input features.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{y}|\mathbf{x})=\sum_{k=1}^M \pi_k(\mathbf{x}) \mathcal{N}(\mathbf{y}; \mu_k(\mathbf{x}), \sigma_k^2(\mathbf{x}))&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt; is the number of components in the mixture and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{N}(\mathbf{y}; \mu_k(\mathbf{x}), \sigma_k^2(\mathbf{x})) = \frac{1}{(2\sigma_k^2(\mathbf{x}))^{c/2}}\exp\left[\frac{||\mathbf{y}-\mu_k(\mathbf{x})||^2}{2\sigma_k^2(\mathbf{x})}\right]&lt;/script&gt;

&lt;p&gt;The mixture weights &lt;script type=&quot;math/tex&quot;&gt;\pi_k(\mathbf{x})&lt;/script&gt; represents the relative amounts by of each mixture components which can be intrepreted as the probabilities of the &lt;script type=&quot;math/tex&quot;&gt;k-&lt;/script&gt; components for a given observation &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt;.If we introduce a latent variable &lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}&lt;/script&gt; with &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; possible states, then &lt;script type=&quot;math/tex&quot;&gt;\pi_k(\mathbf{x})&lt;/script&gt; will represents the probability distribution of these states &lt;script type=&quot;math/tex&quot;&gt;p(\mathbf{z})&lt;/script&gt;. Specifically the MDN converts the input vector using DNN with an output layer &lt;script type=&quot;math/tex&quot;&gt;\mathbf{z}&lt;/script&gt; of linear units to obtain output
 &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathbf{z}} = f(\mathbf{x}, \mathbf{\theta})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;The total number of networks outputs i.e the dimension of &lt;script type=&quot;math/tex&quot;&gt;\hat{\mathbf{z}} \text{ is } (c+2)\cdot M&lt;/script&gt; compared to the usual &lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; outputs for a network used in the conventional manner. In order to gurantee that &lt;script type=&quot;math/tex&quot;&gt;p(\mathbf{y}|\mathbf{x})&lt;/script&gt; is a probability distribution, the outputs of the networks need to be constrained such that the variance should remains positive and the mixing coefficients lie between zero and one and sum to one. To achieve these constraints:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The mean of the &lt;script type=&quot;math/tex&quot;&gt;k-th&lt;/script&gt; kernel is modelled directly as the network outputs:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mu_{k}^i(\mathbf{x})=z_{k}^{\mu i} \text{  where } i = 1,\ldots, c&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The variances &lt;script type=&quot;math/tex&quot;&gt;\sigma_k&lt;/script&gt; is represented by an exponential activation function of the corrensponding network output.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma_k(\mathbf{x}) = \exp(z_k^{\sigma})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;The mixing coefficient &lt;script type=&quot;math/tex&quot;&gt;\pi _k(\mathbf{x})&lt;/script&gt;  is modelled as the softmax transformation of the corresponding output.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\pi_k = \frac{\exp(z_k^{\pi})}{\sum_{j=1}^M \exp(z_j^{\pi})}&lt;/script&gt;

&lt;h2 id=&quot;training-mdn&quot;&gt;Training MDN&lt;/h2&gt;
&lt;p&gt;As the generative model, an MDN model can be trained using the back propagation algorithm under the maximum likelihood criterion. Suppose &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is the vector of trainable parameter, we can redefine our model as a function of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; parameterized by &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{y}|\mathbf{x}, \mathbf{\theta})=\sum_{k=1}^M \pi_k(\mathbf{x}, \mathbf{\theta}) \mathcal{N}(\mathbf{y}; \mu_k(\mathbf{x}, \mathbf{\theta}), \sigma_k^2(\mathbf{x}, \mathbf{\theta}))&lt;/script&gt;

&lt;p&gt;Considering a data set &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}= \{ \mathbf{x}_{1:N},\mathbf{y}_{1:N}\}&lt;/script&gt; 
we want to maximize&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{\theta}|\mathcal{D}) = p(\mathbf{\theta}|\mathbf{Y},\mathbf{X})&lt;/script&gt;

&lt;p&gt;By Bayes’s theorem this is equivalent to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{\theta}|\mathbf{Y},\mathbf{X})p(\mathbf{Y}) = p(\mathbf{Y},\mathbf{\theta} |\mathbf{X}) = p(\mathbf{Y}|\mathbf{X},\mathbf{\theta})p(\mathbf{\theta})&lt;/script&gt;

&lt;p&gt;which leads to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{\theta}|\mathbf{Y},\mathbf{X}) = \frac{p(\mathbf{Y}|\mathbf{X},\mathbf{\theta})p(\mathbf{\theta})}{p(\mathbf{Y})} \propto p(\mathbf{Y}|\mathbf{X},\mathbf{\theta})p(\mathbf{\theta})&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\mathbf{Y}|\mathbf{X},\mathbf{\theta})=\prod_{n=1}^N p(\mathbf{y}_n|\mathbf{x}_n, \mathbf{\theta})&lt;/script&gt;

&lt;p&gt;which is simply the product of the conditional densities for each pattern.&lt;/p&gt;

&lt;p&gt;To define an error function, the standard approach is the maximum likelihood method, which requires maximisation of the log-likelihood function or, equivalently, minimisation of the negative logarithm of the likelihood. Therefore, the error function for the Mixture Density Network is:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
E(\theta, \mathcal{D})&amp;=-\log p(\mathbf{\theta}|\mathbf{Y},\mathbf{X})= -\log p(\mathbf{Y}|\mathbf{X},\mathbf{\theta})p(\mathbf{\theta})\\
&amp;= -\left(\log \prod_{n=1}^N p(\mathbf{y}_n|\mathbf{x}_n, \mathbf{\theta}) + \log p(\mathbf{\theta})\right)\\
&amp;=-\left(\sum_{n=1}^N \log \sum_{k=1}^M \pi_k(\mathbf{x}) \mathcal{N}(\mathbf{y}; \mu_k(\mathbf{x}), \sigma_k^2(\mathbf{x})) + \log p(\mathbf{\theta})\right)\\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;If we assume a non-informative prior of &lt;script type=&quot;math/tex&quot;&gt;p(\mathbf{\theta})=1&lt;/script&gt; the error function simplify to&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E(\theta, \mathcal{D}) = -\sum_{n=1}^N \log \sum_{k=1}^M \pi_k(\mathbf{x}) \mathcal{N}(\mathbf{y}; \mu_k(\mathbf{x}), \sigma_k^2(\mathbf{x}))&lt;/script&gt;

&lt;h2 id=&quot;python-implementataion&quot;&gt;Python Implementataion&lt;/h2&gt;

&lt;h3 id=&quot;multi-layer-percetron&quot;&gt;Multi-layer Percetron&lt;/h3&gt;
&lt;p&gt;Let first create a&lt;/p&gt;

&lt;h3 id=&quot;training-multilayer-perceptrons&quot;&gt;Training Multilayer Perceptrons&lt;/h3&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction Deep Learning models are widely used in prediction problem which involve learning associate mapping from set of inputs variables to a set of output variables where is the size of input features and is the dimension of the output feature or target. In this case usually the network is trained using minimization of sum of squares errors or cross entropy error function over a set of training data of the form</summary></entry><entry><title type="html">Learning HMM parameters for Continous Density Models</title><link href="https://sambaiga.github.io/ml/hmm/2017/06/12/hmm-gausian.html" rel="alternate" type="text/html" title="Learning HMM parameters for Continous Density Models" /><published>2017-06-12T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>https://sambaiga.github.io/ml/hmm/2017/06/12/hmm-gausian</id><content type="html" xml:base="https://sambaiga.github.io/ml/hmm/2017/06/12/hmm-gausian.html">&lt;p&gt;In the previous post we considered a scenario in which observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; are discrete symbols. However, for many practical problems the observation symbols are continous vectors. As the results the contious probability desnsity function (pdfs) are used to model the space of the observation signal associated with each state. Most commonly used emission distribution are gaussian distribution and the gausian mixture models.&lt;/p&gt;

&lt;h3 id=&quot;gaussian-distribution-and-the-gausian-mixture-models&quot;&gt;Gaussian Distribution and the Gausian Mixture Models&lt;/h3&gt;

&lt;p&gt;It is popular to represent the randomness of continuous-valued  using the multivariate Gaussian distribution. A vector-valued random variable &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; is said to have a multivariate normal (or Gaussian) distribution with mean &lt;script type=&quot;math/tex&quot;&gt;\mu=\mathop{\mathbf{E[x]}}&lt;/script&gt; and covariance matrix &lt;script type=&quot;math/tex&quot;&gt;\Sigma=\mathbf{cov[x]}&lt;/script&gt; if:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbf{x}; \mu, \Sigma) = \mathcal{N(\mathbf{x} \mid \mu, \Sigma)}=\frac{1}{(2\pi)^{D/2} |\Sigma|^\frac{1}{2}}\quad\exp\Big(-\frac{1}{2}[\mathbf{x} - \mu] \Sigma^{-1}[\mathbf{x} - \mu]^\mathsf{T} \Big)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; is the dimensionality of &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt;. The &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; represents the location where samples are most likely to be generated and the &lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt; indicates the level to which two variables vary together.&lt;/p&gt;

&lt;p&gt;However, a single Gaussian distribution is insufficient to represent the state-dependent observation space for an HMM state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; because there are large amounts of training data collected from various appliance instances with different modes, distortions, background noises, etc which are used to train the parameters of individual HMM states. In this case, a Gaussian mixture model (GMM) is adopted to represent the state-dependent observation space.&lt;/p&gt;

&lt;p&gt;A mixture model is a probabilistic model for density estimation using a mixture distribution and can be regarded as a type of unsupervised learning or clustering. They provide a method of describing more complex propability distributions, by combining several probability distributions. A multivariate Gaussian mixture distribution is given by the following equation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbf{x}) = \displaystyle\sum_{k=1}^{K}\omega_k \mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)}&lt;/script&gt;

&lt;p&gt;The parameters &lt;script type=&quot;math/tex&quot;&gt;\omega_k&lt;/script&gt; are called mixing coefficients, which must fulfill&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\displaystyle\sum_{k=1}^{K}\omega_k =1&lt;/script&gt;

&lt;p&gt;and given &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)} \geq 0&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;P(\mathbf{x}) \geq 0&lt;/script&gt; we also have that 
&lt;script type=&quot;math/tex&quot;&gt;0\leq \omega_k \geq 1&lt;/script&gt;. Each Gaussian density &lt;script type=&quot;math/tex&quot;&gt;\mathcal{N(\mathbf{x} \mid \mu_k, \Sigma_k)}&lt;/script&gt; is
called a component of the mixture and has its own mean &lt;script type=&quot;math/tex&quot;&gt;\mu_k&lt;/script&gt;   and covariance &lt;script type=&quot;math/tex&quot;&gt;\Sigma_k&lt;/script&gt;.&lt;/p&gt;

&lt;h3 id=&quot;hmm-with-gaussian-emission-distribution&quot;&gt;HMM with gaussian emission distribution&lt;/h3&gt;

&lt;p&gt;If the observations are continuous, it is common for the emission probabilities to be a conditional
Gaussian such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathbb{y_t} \mid s_t =i) = \mathcal{N(\mathbf{y_t} \mid \mu_i, \Sigma_i)}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\mu_i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\Sigma_i&lt;/script&gt; are mean vector and covariance matrix associated with state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The re-estimation formula for the mean vector and covariance matrix of a state gausian pdf can be derived as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \hat{\mu}_i &amp; =\frac{\displaystyle\sum_{t=1}^{T}\gamma_t(i)\mathbb{y(t)}}{\displaystyle\sum_{t=1}^{T}\gamma _t(i)}\\
 \hat{\Sigma}_i &amp; =\frac{\displaystyle\sum_{t=1}^{T}\gamma_t(i) [\mathbf{y(t)}-\hat{\mu}_i]\cdot[\mathbf{y(t)}-\hat{\mu}_i]^T}{\displaystyle\sum_{t=1}^{T}\gamma_t(i)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;hmms-with-gaussian-mixture-model&quot;&gt;HMMs with Gaussian Mixture Model&lt;/h3&gt;

&lt;p&gt;In HMMs with gaussian mixture pdf, the emission probabilities is given by&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\mathbb{y_t} \mid s_t =i) = \displaystyle\sum_{k=1}^{M} \omega\_{ik}\mathcal{N(\mathbb{y_t} \mid \mu_{ik}, \Sigma_{ik})}&lt;/script&gt;
  where &lt;script type=&quot;math/tex&quot;&gt;\omega_{ik}&lt;/script&gt; is the prior probability of the  &lt;script type=&quot;math/tex&quot;&gt;k^{th}&lt;/script&gt; component of the mixture.&lt;/p&gt;

&lt;p&gt;The posterior probability of state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and state &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=j&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \gamma_t(i,j)&amp; =P(s_t=i, s_{t+1}=j \mid Y, \lambda) \\
 &amp; = \frac{\alpha_t(i)a_{ij}\Big[ \displaystyle\sum_{k=1}^{M} \omega_{ik}\mathcal{N(\mathbf{y_t} \mid \mu_{ik}, \Sigma_{ik})} \Big]\beta_{t+1}(j)}{\displaystyle\sum_{i=1}^{N}\alpha_T(i)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;and the posterior probability of state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and observation &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) =\frac{\alpha_t(i)\beta_t(i)}{\displaystyle\sum_{i=1}^{N}\alpha _T(i)}&lt;/script&gt;

&lt;p&gt;Let define the joint posterior probability of the state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; and the &lt;script type=&quot;math/tex&quot;&gt;k^{th}&lt;/script&gt; gaussian component pdf of state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\xi(i,k) &amp;= P(S_t=s_i, m(t)=k \mid Y, \lambda) \\
 &amp;=\frac{\displaystyle\sum_{j=1}^{N} \alpha_t(j) a_{ij} \omega_{ik}\mathcal{N(\mathbf{y_t} \mid \mu_{ik}, \Sigma_{ik})}\beta_{t+1}(j)}{\displaystyle\sum_{i=1}^{N}\alpha _T(i)} 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The re-estimation formula for the mixture coefficeints, the mean vectors and the covariance matrices of the state mixture gausian pdf as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
 \hat{\omega}_{ik} &amp;= \frac{\displaystyle \sum_{t=1}^{T} \xi_t(i,k)}{\displaystyle\sum\_{t=0}^{T}\gamma_t(i)} \\
\hat{\mu}_{ik} &amp;= \frac{\displaystyle\sum\ _{t=1}^{T}\xi\ _t(i,k)\mathbf{y_t}}{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)} \\
\hat{\Sigma}_{ik}&amp;=\frac{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)[\mathbf{y_t}-\hat{\mu}_{ik}]\cdot[\mathbf{y_t}-\hat{\mu}_{ik}]^T}{\displaystyle\sum_{t=1}^{T}\xi_t(i,k)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;limitation-of-baumwelch-algorithm&quot;&gt;Limitation of Baum–Welch algorithm&lt;/h3&gt;

&lt;p&gt;When applying Baum–Welch algorithm  in real  data, we need to consider some heuristics in the ML EM algorithm.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;How to provide initial parameters values. This is always an important question, and it is usually resolved by using a simple algorithm (e.g., K-means clustering or random initialization).&lt;/li&gt;
  &lt;li&gt;How to avoid unstability in the parameter estimation (especially covariance parameter estimation) due to data sparseness. For examle some mixture components or hidden states cannot have sufficient data assigned in the Viterbi or forward–backward algorithm. This can be heuristically avoided by setting a threshold to update these parameters, or setting minimum threshold values for covariance parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The above two problem can be solved by the Bayesian approaches.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Saeed V. Vaseghi, Advanced Digital Signal Processing and Noise Reduction. John Wiley &amp;amp; Sons, 2008.&lt;/li&gt;
  &lt;li&gt;Kevin P. Murphy, Machine Learning: A Probabilistic Perspective. The MIT Press Cambridge, Massachusetts, 2012.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">In the previous post we considered a scenario in which observation sequences are discrete symbols. However, for many practical problems the observation symbols are continous vectors. As the results the contious probability desnsity function (pdfs) are used to model the space of the observation signal associated with each state. Most commonly used emission distribution are gaussian distribution and the gausian mixture models.</summary></entry><entry><title type="html">Learning HMM parameters with Discrete Observation Models</title><link href="https://sambaiga.github.io/ml/hmm/2017/05/29/hmm-discrete.html" rel="alternate" type="text/html" title="Learning HMM parameters with Discrete Observation Models" /><published>2017-05-29T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>https://sambaiga.github.io/ml/hmm/2017/05/29/hmm-discrete</id><content type="html" xml:base="https://sambaiga.github.io/ml/hmm/2017/05/29/hmm-discrete.html">&lt;p&gt;In Previous post we discussed the basic of HMM modeling given model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and  compute the likelihood values etc, efficiently based on the forward, backward, and Viterbi algorithms. In the like manner, we can efficiently train the HMM to obtain the model parameter &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; from data. In this post we will discuss different methods for training HMM models.&lt;/p&gt;

&lt;p&gt;This is the solution to Problem 3 which involve determining a method to learn model parameters &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; given the sequence of observation variables &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;. Given the observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; as training data, there is no optimal way of estimating the model parametrs. However, using iterative procedure we can choose &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda} = (\hat{A},\hat{B},\hat{\pi})&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; is locally maximized.The most common produre which has been employed to his problem is the &lt;strong&gt;Baum-Welch&lt;/strong&gt; method.&lt;/p&gt;

&lt;h3 id=&quot;baum-welch-methods&quot;&gt;Baum-Welch Methods&lt;/h3&gt;

&lt;p&gt;This method assume an initial model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; which should be adjusted so as to increase &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt;. The initial parametrs can be constructed in any way or employ the first five procedure of the &lt;a href=&quot;http://www.ece.ucsb.edu/Faculty/Rabiner/ece259/Reprints/segmental%20k-means%20algorithm.pdf&quot;&gt;Segmental K-means algorithm&lt;/a&gt;. The optimazation criteria is called the &lt;strong&gt;maximum likelihood criteria&lt;/strong&gt;.The function &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; is called the &lt;strong&gt;likelihood function&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;the-e-m-auxilliary-function&quot;&gt;The E-M Auxilliary Function&lt;/h3&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; represent the current model and &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt; represent the candidate models. The learning objective is to make: &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat{\lambda}) \geq P(Y \mid \lambda)&lt;/script&gt; which is equivalently to &lt;script type=&quot;math/tex&quot;&gt;\log[P(Y \mid \hat{\lambda})] \geq \log [P(Y\mid \lambda)]&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Let also define the auxilliary function &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt; such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\lambda}\mid \lambda) &amp; = \mathbb{E}\Big[\log P(Y,S \mid \hat{\lambda})\mid Y, \lambda \Big] \\
                            &amp; = \sum_s P(S \mid Y, \lambda)\cdot \log [P(Y,S\mid \hat{\lambda})]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The Maximum Likehood Estimation (MLE) of the model parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for complete data &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and hidden state &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; is;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\lambda} = \arg\max _{\lambda} \sum_s P(Y, S \mid \lambda)&lt;/script&gt;

&lt;p&gt;However due to the presence of several stochatsic constraints it turns out to be easier to mximize uxilliary function &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt; rather than directly maximize &lt;script type=&quot;math/tex&quot;&gt;P(Y\mid \hat{\lambda})&lt;/script&gt;. Thus the MLE of the model parameter &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; for complete data &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and hidden state &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\lambda} = \arg\max _{\lambda} Q(\hat{\lambda}\mid\lambda)&lt;/script&gt;

&lt;p&gt;It can be shown that the parameter estimated by the EM procedure, &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\lambda}\mid \lambda)&lt;/script&gt;, always increases the likelihood value. You may concert &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;reference 2&lt;/a&gt; chapter 3 for details on the prove.&lt;/p&gt;

&lt;h3 id=&quot;expectation-step&quot;&gt;Expectation step&lt;/h3&gt;

&lt;p&gt;To find ML estimates of HMM parameters, we first expand the auxiliary function rewrite it by substituting the joint distribution of complete data likelihood.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\lambda} \mid \lambda) &amp; = \mathbf{E}\Big[\log P(Y,S\mid\hat{\lambda})\mid Y, \lambda \Big] \\
&amp; = \sum_s P(S\mid Y, \lambda)\cdot \log [P(Y,S\mid\hat{\lambda})] \\
&amp; = \sum_s P(S\mid Y, \lambda)\cdot \Big[\log \hat{\pi}_1 + \log \hat{b}_1(y_1) + \sum _{t=2}^T\big( \log \hat{a} _{ij} + \log \hat{b}_i({y_t})\big)\Big] 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We have three term to solve:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The initial probability &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}&lt;/script&gt; ,&lt;/li&gt;
  &lt;li&gt;State transition probability &lt;script type=&quot;math/tex&quot;&gt;\hat{A} = \hat{a}_{ij}&lt;/script&gt; and&lt;/li&gt;
  &lt;li&gt;Emission probability &lt;script type=&quot;math/tex&quot;&gt;\hat{B} = \hat{b}_i(y_t)&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let first define important parameters that we will use. For &lt;script type=&quot;math/tex&quot;&gt;t = 1,2...T&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq j \geq N&lt;/script&gt;, we define:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\xi_t(i,j)=P(s_t=i, s_{t+1}=j \mid Y, \lambda)&lt;/script&gt;

&lt;p&gt;an expected transition probability from &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; to , &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=j&lt;/script&gt;. The probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and state &lt;script type=&quot;math/tex&quot;&gt;s_j&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and observation sequences &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\xi_t(i,j)&lt;/script&gt; can be written in terms of forward &lt;script type=&quot;math/tex&quot;&gt;\alpha_t(i)&lt;/script&gt; and backward &lt;script type=&quot;math/tex&quot;&gt;\beta_{t+1}(j)&lt;/script&gt; variables as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}   
\xi_t(i,j) &amp;= \frac{\alpha_t(i)a_{ij}b_i(y_{t+1})\beta_{t+1}(j)}{P(Y \mid \lambda)} \\ 
          &amp;= \frac{\alpha_t(i)a_{ij}b_i(y_{t+1})\beta_{t+1}(i)}{\displaystyle \sum_{i=1}^{N}\displaystyle \sum_{j=1}^{N}\alpha_t(i)a_{ij}b_j(y_{t+1})\beta_{t+1}(j)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where the numerator term is just &lt;script type=&quot;math/tex&quot;&gt;P(S_t=s_i, S_{t+1}=s_j \mid Y, \lambda)&lt;/script&gt;  and the division by &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; gives the desire probability measures.&lt;/p&gt;

&lt;p&gt;We have previosly difined &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i) =  \frac{\alpha_t(i)\beta_t(i)}{P(Y \mid \lambda)}&lt;/script&gt; as the probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the observation sequence and model parameter. &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; relate to &lt;script type=&quot;math/tex&quot;&gt;\xi_t(i,j)&lt;/script&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) = \displaystyle\sum_{j=1}^{N}\xi_t(i,j)&lt;/script&gt;

&lt;p&gt;It follows that:&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle\sum_{t=1}^{T-1}\gamma_t(i)=&lt;/script&gt; Expected number of transitions from state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; .&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\displaystyle\sum_{t=1}^{T-1}\xi_t(i,j)=&lt;/script&gt; Expected number of transitions from state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; to state &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;We provide the solution for each term. Considering the first term  &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi} \mid \pi)&lt;/script&gt; we define the following auxiliary function for &lt;script type=&quot;math/tex&quot;&gt;\pi _i&lt;/script&gt;  as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{\pi}\mid \pi) = \sum_s P(S\mid Y, \lambda)\cdot \log \hat{\pi}_{s_1}&lt;/script&gt;

&lt;p&gt;Since &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_{s_1}&lt;/script&gt; only depends on &lt;script type=&quot;math/tex&quot;&gt;s_1&lt;/script&gt;, it clear that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(S\mid Y, \lambda) = P(s_1\mid Y, \lambda)&lt;/script&gt;

&lt;p&gt;Therefore &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi}\mid pi)&lt;/script&gt;  can be rewritten as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{\pi}\mid \pi) &amp;= \sum_{s_1}P(s_1 \mid Y, \lambda)\cdot \log \hat{\pi}_{s_1} \\
                     &amp;= \sum_{i=1}^N P(s_1=i \mid Y, \lambda)\cdot \log \hat{\pi}_{i} \\
                     &amp; = \sum_{i=1}^N \gamma_t(i) \log \hat{\pi}_{i}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Next, we focus on the second term &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{A}\mid A)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{A}\mid A) = \sum_s P(S\mid Y, \lambda) \cdot \sum _{t=2}^T  \log \hat{a}_{s_t,s_{t+1}}&lt;/script&gt;

&lt;p&gt;Similar to &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi}\mid \pi)&lt;/script&gt; , we obtain
&lt;script type=&quot;math/tex&quot;&gt;P(S\mid Y, \lambda) = P(s_1\mid Y, \lambda) = P(s_t,s_{t+1}\mid Y, \lambda)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{A}\mid A) &amp; =  \sum _{t=1}^{T-1}  \sum_s P(s_t,s_{t+1}\mid Y, \lambda) \log \hat{a}_{s_t,s_{t+1}} \\
 &amp; = \sum _{t=1}^{T-1} \sum_{i=1}^N \sum_{j=1}^N P(s_t=i,s_{t+1}=j\mid Y, \lambda) \log \hat{a}_{ij} \\
&amp; = \sum _{t=1}^{T-1} \sum_{i=1}^N \sum_{j=1}^N \xi_t(i,j) \log \hat{a}_{ij}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Finally, we focus on the last term &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{B}\mid B)&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{B}\mid B) = \sum_s P(S\mid Y, \lambda)\cdot \sum _{t=1}^T  \log \hat{b}_{i}(y_t)&lt;/script&gt;

&lt;p&gt;Similary &lt;script type=&quot;math/tex&quot;&gt;P(S\mid Y, \lambda) = P(s_t = i\mid Y, \lambda)&lt;/script&gt;. Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Q(\hat{B}\mid B) &amp;= \sum _{t=1}^T \sum_s P(s_t = i\mid Y, \lambda) \log \hat{b}_{i}(y_t) \\
&amp; = \sum _{t=1}^T \sum_{i=1}^N \gamma_t(i)\log \hat{b}_{i}(y_t)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus, we summarize the auxiliary function&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q(\hat{\lambda}\mid \lambda)= Q(\hat{\pi}\mid \pi)+ Q(\hat{A}\mid A) + Q(\hat{B}\mid B)&lt;/script&gt;

&lt;h3 id=&quot;maximization-step&quot;&gt;Maximization step&lt;/h3&gt;

&lt;p&gt;In the maximization step, we aim to maximize &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{\pi} \mid \pi)&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{A} \mid A)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;Q(\hat{B} \mid B)&lt;/script&gt; with respect to &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}&lt;/script&gt;, &lt;script type=&quot;math/tex&quot;&gt;\hat{A}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{B}&lt;/script&gt; under the following constraints.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum\_{i=1}^N \hat{\pi} = 1, \text{ and } \sum_{i=1}^N \hat{A} = 1&lt;/script&gt;

&lt;p&gt;Considering the estimation of initial state probabilities &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\hat{\pi}} = {\hat{\pi}_i}&lt;/script&gt; , we construct a Lagrange function (or Lagrangian):&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q^*(\hat{\pi} \mid \pi) =\sum_{i=1}^N \gamma_1(i) \log \hat{\pi}_{i} + \eta \left(\sum_{i=1}^N \hat{\pi} - 1 \right)&lt;/script&gt;

&lt;p&gt;Differentiating this Lagrangian with respect to individual probability parameter &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_i&lt;/script&gt;  and set it to zero we obtain.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial Q^*(\hat{\pi} \mid \pi)}{\partial \hat{\pi}_i } &amp; = \gamma_1(i) \frac{1}{\hat{\pi}_i} + \eta = 0 \\
\hat{\pi}_i &amp;=  - \frac{1}{\eta}\gamma_1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Substituting the above equation into &lt;script type=&quot;math/tex&quot;&gt;\sum_{i=1}^N \hat{\pi} = 1&lt;/script&gt; constraint, we obtain:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\sum_{i=1}^N \hat{\pi} &amp;= \sum_{i=1}^N - \frac{1}{\eta}\gamma_1(i) = 1 \\
\Rightarrow \eta &amp;= - \sum_{i=1}^N \gamma_1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The ML estimate of new initial state probability is obtained by substituting the above equation into &lt;script type=&quot;math/tex&quot;&gt;\hat{\pi}_i =  - \frac{1}{\eta}\gamma_1(i)&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\pi}_i = \frac{\gamma_1(i)}{\sum _{i=1}^N \gamma_1(i)} = \gamma_1(i)&lt;/script&gt;

&lt;p&gt;In the same manner, we can derive the ML estimates of new state transition probability and new emission probability, which can be shown to be:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{a}_{ij} = \frac{\displaystyle \sum_{t=1}^{T-1}\xi_t(i,j)}{\displaystyle\sum_{t=1}^{T-1}\gamma_t(i)}&lt;/script&gt;

&lt;p&gt;And&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{b}_i(k) = \frac{\displaystyle\sum_{t=1}^{T}\tau \gamma_t(i)}{\displaystyle\sum_{t=1}^{T} \gamma_t(i)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tau =
 \begin{cases}
1 \text{ if } y_t = k, \\ 0  \text{ otherwise }
\end{cases}&lt;/script&gt;

&lt;p&gt;If we denote the initial model &lt;script type=&quot;math/tex&quot;&gt;{\lambda}&lt;/script&gt; and the re-estimation model by &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}=(\hat{\pi}_i, \hat{a}_{ij},\hat{b}_j(k))&lt;/script&gt;. Then i t can be shown that either:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The initial model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; is a critical point of the likelihood in which case &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}= \lambda&lt;/script&gt; or&lt;/li&gt;
  &lt;li&gt;&lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat\lambda) \leq P(Y \mid \lambda)&lt;/script&gt;, i.e we have find the better model from which the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y=y_1,\ldots Y_T&lt;/script&gt; is more likely to be produced.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hence we can go on iteractively computing until &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \hat{\lambda})&lt;/script&gt; is maximazed.&lt;/p&gt;

&lt;p&gt;The Baum-Welch Algorithm can be summerized as:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Require&lt;/strong&gt;: &lt;script type=&quot;math/tex&quot;&gt;\lambda \leftarrow \lambda ^{init}&lt;/script&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt; &lt;strong&gt;repeat&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;  Compute the forward variable &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)&lt;/script&gt; from the forward algorithm&lt;/li&gt;
  &lt;li&gt;  Compute the backward variable &lt;script type=&quot;math/tex&quot;&gt;\beta _t(i)&lt;/script&gt; from the backward algorithm&lt;/li&gt;
  &lt;li&gt;  Compute the occupation probabilities &lt;script type=&quot;math/tex&quot;&gt;\gamma _t(i)&lt;/script&gt;,  and &lt;script type=&quot;math/tex&quot;&gt;\xi _t(i,j)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;  Estimate the new HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\hat{\lambda}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;  Update the HMM parameters   &lt;script type=&quot;math/tex&quot;&gt;\lambda \leftarrow \hat{\lambda}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt; &lt;strong&gt;until&lt;/strong&gt; Convergence&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;L. R. Rabiner, &lt;a href=&quot;http://www.cs.ucsb.edu/~cs281b/papers/HMMs%20-%20Rabiner.pdf&quot;&gt;A tutorial on hidden Markov models and selected applications in speech recognition&lt;/a&gt;, Proceedings of the IEEE, Vol. 77, No. 2, February 1989.&lt;/li&gt;
  &lt;li&gt;Shinji Watanabe, Jen-Tzung Chien, &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;Bayesian Speech and Language Processing&lt;/a&gt;, Cambridge University Press, 2015.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.vocal.com/echo-cancellation/viterbi-algorithm-in-speech-enhancement-and-hmm/&quot;&gt;Viterbi Algorithm in Speech Enhancement and HMM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Nikolai Shokhirev, &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">In Previous post we discussed the basic of HMM modeling given model parameters and compute the likelihood values etc, efficiently based on the forward, backward, and Viterbi algorithms. In the like manner, we can efficiently train the HMM to obtain the model parameter from data. In this post we will discuss different methods for training HMM models.</summary></entry><entry><title type="html">The Basic of Hidden Markov Model</title><link href="https://sambaiga.github.io/2017/05/03/hmm-intro.html" rel="alternate" type="text/html" title="The Basic of Hidden Markov Model" /><published>2017-05-03T00:00:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>https://sambaiga.github.io/2017/05/03/hmm-intro</id><content type="html" xml:base="https://sambaiga.github.io/2017/05/03/hmm-intro.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;HMM is a Markov model whose states are not directly observed instead each state is characterised by a probability distribution function modelling the observation corresponding to that state. HMM has been extensively used in temporal pattern recognition such as speech, handwriting, gesture recognition, robotics, biological sequences and recently in energy disaggregation. This tutorial will introduce the basic concept of HMM.&lt;/p&gt;

&lt;p&gt;There are two variables in HMM: observed variables and hidden variables where the sequences of hidden variables forms a Markov process as shown in figure below. In the context of NILM, the hidden variables are used to model states(ON,OFF, standby etc) of individual appliances and the observed variables are used to model the electric usage. HMMs has been widely used in most of the recently proposed NILM approach because it represents well the individual appliance internal states which are not directly observed in the targeted energy consumption.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&quot;/assets/img/post/hmm.png&quot; title=&quot;HMM graphical model&quot; alt=&quot;&quot; /&gt;
  &lt;figcaption&gt;HMM graphical model
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;A typical HMM is characterised by the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The finite set of hidden states  &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; (e.g ON, stand-by, OFF, etc.) of an appliance,  &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1, s_2....,s_N\}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;The finite set of  &lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt; observable symbol  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; per states (power consumption) observed in each state,  &lt;script type=&quot;math/tex&quot;&gt;Y = \{y_1, y_2....,y_M\}&lt;/script&gt;. The observable symbol  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; can be discrete or a continuous set.&lt;/li&gt;
  &lt;li&gt;The transition matrix   &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}=\{a_{ij},1\leq i,j \geq N\}&lt;/script&gt; represents the probability of moving from state  &lt;script type=&quot;math/tex&quot;&gt;s_{t-1}=i&lt;/script&gt; to  &lt;script type=&quot;math/tex&quot;&gt;s_t =j&lt;/script&gt; such that:  &lt;script type=&quot;math/tex&quot;&gt;a_{ij} = P(s_{t} =j \mid s_{t-1}=i)&lt;/script&gt;, with  &lt;script type=&quot;math/tex&quot;&gt;a_{ij} \leq 0&lt;/script&gt; and where  &lt;script type=&quot;math/tex&quot;&gt;s_t&lt;/script&gt; denotes the state occupied by the system at time  &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;. The matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}&lt;/script&gt; is  &lt;script type=&quot;math/tex&quot;&gt;N x N&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;The emission matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{B} =\{b_j(k)\}&lt;/script&gt; representing the probability of emission of symbol  &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;  &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;  &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; when system state is  &lt;script type=&quot;math/tex&quot;&gt;s_t=j&lt;/script&gt; such that:  &lt;script type=&quot;math/tex&quot;&gt;b_j(k) = p(y_t = k  \mid  s_t=j)&lt;/script&gt; The matrix  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{B}&lt;/script&gt; is an  &lt;script type=&quot;math/tex&quot;&gt;N x M&lt;/script&gt;. The emission probability can be discrete or continous distribution. If the emission is descrete a multinomial distribution is used and multivariate Gaussian distribution is usually used for continous emission.&lt;/li&gt;
  &lt;li&gt;And the initial state probability distribution  &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\pi}  = \{\pi_i \}&lt;/script&gt; indicating the probability of each state of the hidden variable  at  &lt;script type=&quot;math/tex&quot;&gt;t = 1&lt;/script&gt; such that,  &lt;script type=&quot;math/tex&quot;&gt;\pi _i = P(q_1 = s_i), 1 \leq i \geq N&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The complete HMM specification requires;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Finite set of hidden states &lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; and observation symbols &lt;script type=&quot;math/tex&quot;&gt;M&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Length of observation seqences &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; and&lt;/li&gt;
  &lt;li&gt;Specification of three probability measures &lt;script type=&quot;math/tex&quot;&gt;\mathbf{A}, \mathbf{B}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\pi}&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The set of all HMM model parameters is represented by &lt;script type=&quot;math/tex&quot;&gt;\mathbf{\lambda} =(\pi, A, B)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Since &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; is not observed, the likelihood function &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is given by the joint distribution of &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; over all possible state.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid \lambda) = \sum P(Y, S \mid  \lambda)&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y,S \mid \lambda) = P(Y \mid S,\lambda)P(S \mid \lambda)&lt;/script&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;y_t&lt;/script&gt; is independent and identically distributed given state sequence &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1, s_2....,s_N\}&lt;/script&gt;. Also each state at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; depend on the state at its previous time &lt;script type=&quot;math/tex&quot;&gt;t-1&lt;/script&gt;. Then&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid S, \lambda) = \prod_{t=1}^T P(y_t \mid s_t)&lt;/script&gt;

&lt;p&gt;Similary&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(S \mid \lambda) = \pi _{s_1} \prod _{t=2}^T a_{ij}&lt;/script&gt;

&lt;p&gt;The joint probability is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid \lambda) = \pi _{s_1}P(y_1 \mid s_1) \sum \prod_{t=2}^T a_{ij} P(y_t \mid s_t)&lt;/script&gt;

&lt;h2 id=&quot;three-main-problems-in-hmms&quot;&gt;Three main problems in HMMs&lt;/h2&gt;

&lt;p&gt;When applying HMM to a real world problem, three important problem must be solved.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Evaluation Problem: Given HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; the likelihood of the observation sequence &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;. This problem give a score on how well a given model matches a given observation and thus allows you to choose the model that best match the observation.&lt;/li&gt;
  &lt;li&gt;Decoding Problem: Given HMM parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; and the observation seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find an optimal state sequense &lt;script type=&quot;math/tex&quot;&gt;S = \{S_1, S_2....,S_N\}&lt;/script&gt; which best explain the observation.This problem attempt to cover the hidden part of the model.&lt;/li&gt;
  &lt;li&gt;Learning Problem: Given the obseravtion seqence &lt;script type=&quot;math/tex&quot;&gt;Y = \{Y_1, Y_2....,Y_M\}&lt;/script&gt;, find the model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt; that maximize &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt;.This problem attempt to optimize the model parameters so as to describe the model.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first and the second problem can be solved by the dynamic programming algorithms known as the Viterbi algorithm and the Forward-Backward algorithm, respectively. The last one can be solved by an iterative Expectation-Maximization (EM) algorithm, known as the Baum-Welch algorithm. We will discuss the first and the second problem in this post.&lt;/p&gt;

&lt;h2 id=&quot;solution-to-problem-1&quot;&gt;Solution to Problem 1&lt;/h2&gt;

&lt;p&gt;A straight forward way to solve this problem is to find &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid S, \lambda)&lt;/script&gt; for fixed state sequences &lt;script type=&quot;math/tex&quot;&gt;S = \{s_1,...s_T \}&lt;/script&gt; and then sum up over all possible states. This is generally infeasible since it requires about &lt;script type=&quot;math/tex&quot;&gt;2TN^T&lt;/script&gt; multiplications. However this problem can be efficiently solved by using the forward algorithm  as follows:&lt;/p&gt;

&lt;h3 id=&quot;the-forward-backward-algorithm&quot;&gt;The forward-backward Algorithm&lt;/h3&gt;

&lt;p&gt;Let us define the &lt;strong&gt;forward variable&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha _t(i)=P(y_1,\ldots y_t, s_t=i \mid \lambda)&lt;/script&gt;

&lt;p&gt;the probability of the partial observation sequences &lt;script type=&quot;math/tex&quot;&gt;y_1 \ldots y_t&lt;/script&gt;  up to time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and the state &lt;script type=&quot;math/tex&quot;&gt;s_t =i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the model &lt;script type=&quot;math/tex&quot;&gt;{\lambda}&lt;/script&gt;. We also define an emission probability given HMM state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; as &lt;script type=&quot;math/tex&quot;&gt;b_i(y_t)&lt;/script&gt;.&lt;/p&gt;

&lt;h4 id=&quot;forward-algorithm&quot;&gt;Forward-Algorithm&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\alpha _1(i)&amp;=P(y_1, s_1=i \mid \lambda) \\
    &amp; = P(y_1 \mid s_1=i,\lambda)P(s_1=i \mid \lambda)\\
    &amp;= \pi _i b_i(y_1) \text{  for  } 1\leq i \geq N
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Induction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;t=2,3...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt;, compute:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\alpha _{t}(i) &amp; = P(y_1 \ldots y_t, s_t=i \mid \lambda)\\
 &amp;= \displaystyle \sum_{j=1}^{N} P(y_1 \ldots y_{t}, s_{t-1}=j,s_t=i \mid \lambda) \\
 &amp;= \displaystyle \sum_{j=1}^{N} P(y_t \mid s_t=i, y_1,\ldots y_{t-1}, s_{t-1}=j, \lambda) \\
   &amp;  \times P(s_t=i \mid y_1 \ldots y_{t-1} \ldots , s_{t-1}=j, \lambda) \\
   &amp; \times P(y_1 \ldots y_{t-1}, s_{t-1}=j,\lambda) \\
 &amp; = P(y_t \mid s_t=i,\lambda)\displaystyle \sum_{j=1}^{N} P(s_t=i \mid s_{t-1}=j)\cdot P(y_1, \ldots y_{t-1}, s_{t-1}) \\
&amp; = b_i(y_{t})\displaystyle \sum_{j=1}^{N} \alpha _{t-1}(i)a_{ij}  
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;From &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)=P(y_1,...y_t, s_t=i \mid \lambda)&lt;/script&gt;, it cear that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
P(Y \mid \lambda) &amp;= \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T, s_T = i \mid \lambda) \\
&amp;= \displaystyle \sum_{i=1}^{N}\alpha _T(i)  
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The forward algorithm only requires about &lt;script type=&quot;math/tex&quot;&gt;N^2T&lt;/script&gt; multiplications and is it can be implemented in python as follows.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# returns log P(Y  \mid  model)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# using the forward part of the forward-backward algorithm
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;      
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;backward-algorithm&quot;&gt;Backward Algorithm&lt;/h3&gt;

&lt;p&gt;This is the same as the forward algorithm discussed in the previous sectionexcept that it start at the end and works backward toward the beginning. We first define the &lt;strong&gt;backward variable&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\beta_t(i)=P(y_{t+1},y_{t+2} \ldots y_{T} \mid s_t=i, {\lambda})&lt;/script&gt;: probability of the partial observed sequence from &lt;script type=&quot;math/tex&quot;&gt;t+1&lt;/script&gt; to the end at &lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; given state &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Then &lt;script type=&quot;math/tex&quot;&gt;\beta_t(i)&lt;/script&gt; can be computed recursively as follows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Let &lt;script type=&quot;math/tex&quot;&gt;\beta_{T}(i)= 1&lt;/script&gt;, for &lt;script type=&quot;math/tex&quot;&gt;1 \leq i\geq N&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Induction&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;t =T-1, T-2,\ldots1&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;1 \leq i\geq N&lt;/script&gt; and by using the sum and product rules, we can rewrite &lt;script type=&quot;math/tex&quot;&gt;\beta_t(j)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\beta_t(i)&amp;=P(y_{t+1},\ldots y_{T} \mid s_t=j, {\lambda}) \\
 &amp;= \displaystyle \sum_{i=1}^{N} P(y_{t+1} \ldots y_T, s_{t+1}=i \mid s_t=j, \lambda) \\
 &amp; = \displaystyle \sum_{i=1}^{N} P(y_{t+1} \ldots y_T, s_{t+1}=i, s_t=j, \lambda)\cdot P(s_{t+1}=i \mid s_t=j) \\
 &amp;= \displaystyle \sum_{i=1}^{N} P(y_{t+2} \ldots y_T, s_{t+1}=i, \lambda)\cdot P(y_{t+1} \mid s_{t + 1}=i, \lambda)\cdot P(s_{t+1}=i \mid s_t=j) \\
 &amp; = \displaystyle \sum_{i=1}^{N} a_{ij}b_i(y_{t+1})\beta _{t+1}(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\beta_{0} &amp; = P(Y \mid \lambda) \\
&amp; = \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T, s_1=i) \\
&amp;= \displaystyle \sum_{i=1}^{N} P(y_1,\ldots y_T \mid s_1=i)\cdot P(s_1=i) \\
&amp; = \displaystyle \sum_{i=1}^{N} P(y_1 \mid s_1=i)\cdot P(y_2,\ldots y_T \mid s_1=i)\cdot P(s_1=i) \\
&amp; = \displaystyle \sum_{i=1}^{N} \pi _i b_i(y_1)\beta _1(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Python implementation of forward algorithm is as shown below;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;posterior-probability&quot;&gt;Posterior Probability&lt;/h4&gt;
&lt;p&gt;The forward variable &lt;script type=&quot;math/tex&quot;&gt;\alpha _t(i)&lt;/script&gt; and backward variable &lt;script type=&quot;math/tex&quot;&gt;\beta _t(i)&lt;/script&gt; are used to calculate the posterior probability of a specific case. Now for &lt;script type=&quot;math/tex&quot;&gt;t=1...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i=1..N&lt;/script&gt;, let define posterior probability &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)=P(s_t=i \mid Y, \lambda)&lt;/script&gt; the probability of being in state &lt;script type=&quot;math/tex&quot;&gt;s_t = i&lt;/script&gt; at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; given the observation &lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and the model &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\gamma_t(i) &amp; = \frac{P(s_t=1, Y \mid \lambda)}{P(Y \mid \lambda)} \\
 &amp;=\frac{P(y_1,\ldots y_t, s_t=1, \mid \lambda)}{P(Y \mid \lambda)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Consider:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(y_1,\ldots y_t, s_t=1, \mid \lambda) &amp; = P(y_1,\ldots y_t \mid  s_t=1,\lambda)\cdot P(y_{t+1},\ldots y_T \mid  s_t=1,\lambda)\cdot P(s_t =i  \mid \lambda) \\
 &amp; = \alpha _t(i) \cdot \beta _t(i)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma_t(i) = \frac{\alpha _t(i) \cdot \beta _t(i)}{P(Y \mid \lambda)}&lt;/script&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(Y \mid {\lambda}) =  \displaystyle \sum_{i=1}^{N}\alpha _T(i)&lt;/script&gt;

&lt;p&gt;In python:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;obs_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can use &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; to find the most likely state at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; which is the state &lt;script type=&quot;math/tex&quot;&gt;s_t=i&lt;/script&gt; for which &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i)&lt;/script&gt; is maximum. This algorithm &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;works fine in the case when HMM is ergodic&lt;/a&gt; i.e. there is transition from any state to any other state. If applied to an HMM of another architecture, this approach could give a sequence that may not be a legitimate path because some transitions are not permitted. To avoid this problem &lt;em&gt;Viterbi algorithm&lt;/em&gt; is the most common decoding algorithms used.&lt;/p&gt;

&lt;h3 id=&quot;viterbi-algorithm&quot;&gt;Viterbi Algorithm&lt;/h3&gt;

&lt;p&gt;Viterbi is a kind of dynamic programming algorithm that make uses of a dynamic programming trellis.&lt;/p&gt;

&lt;p&gt;The virtebi algorithm offer an efficient way of finding  the single best state sequence.Let define the highest probability along a single path, at time &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt;, which accounts for the first &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; observations and ends in state &lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; using a new notation:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta_t(i) &amp; = \max_{s_1,\ldots s_{t-1}} P(s_1, \ldots s_t =1, y_1,\ldots y_t \mid \lambda)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;By induction, a recursive formula of &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt; from &lt;script type=&quot;math/tex&quot;&gt;\delta_t(i)&lt;/script&gt;  is derived to calculate this probability as follows:&lt;/p&gt;

&lt;p&gt;Consider the joint distribution appearing in &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt;, which can be rewritten when &lt;script type=&quot;math/tex&quot;&gt;s_{t+1}=i&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;s_t = j&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(s_1,\ldots, s_t=j,s_{t+1}=i, y_1,\ldots y_t, y_{t+1} \mid \lambda) &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\\&amp; \times P(s_{t+1}=i,y_{t+1} \mid s_1, \ldots s_t, y_1, \ldots y_t, \lambda) \\
 &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot P(s_{t+1} \mid s_t, \lambda)\\ &amp; \times P(y_{t+1} \mid s_{t+1},\lambda) \\
  &amp; = P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot a_{ij}b_i(y_{t+1})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Thus &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(i)&lt;/script&gt;  is computed recursively from &lt;script type=&quot;math/tex&quot;&gt;\delta_{t+1}(j)&lt;/script&gt; as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta_{t+1}(i) &amp;= \max_{s_1,\ldots s_{t}=j} P(s_1 \ldots s_t=j, y_1,\ldots y_t  \mid \lambda)\cdot a_{ij}b_i(y_{t+1}) \\
 &amp; = \max_{j}\Big[ \delta_t(j) a_{ij}\Big]\cdot b_i(y_{t+1})
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We therefore need to keep track the state that maximize the above equation so as to backtrack to the single best state sequence in the following Viterbi algorithm:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Initilization&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For &lt;script type=&quot;math/tex&quot;&gt;1 \leq i \geq N&lt;/script&gt;, let:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\delta _1(i)&amp;= \pi _{s_i}b_i(y_1)\\
\Theta _1(i)&amp;=0
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Recursion&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Calculate  the ML (maximum likelihood) state sequences and their probabilities. For &lt;script type=&quot;math/tex&quot;&gt;t=2,3,...T&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;1\leq i \geq N&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\delta_t(i) &amp; = \displaystyle \max_{j\epsilon{1,..N}} \Big[\delta_{t-1}(j)a_{ij}\Big]\cdot b_i(y_t) \\
\Theta_t(i) &amp; = \arg\max_j \Big[\delta_{t-1}(j)a_{ij} \Big] 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Termination&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Retrieve the most likely final state&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \hat{P} &amp;= \displaystyle \max_{j\epsilon{1,..N}}[\delta_T(j)]  \\
\hat{S}_T &amp; = \arg\max_j [\delta_T(j)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;State sequence backtracking&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Retrieve  the most likely state sequences (virtebi path)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{S}_t = \Theta_{t+1}(\hat{S}_{t+1}) \text{, where } t=T-1,T-2,\ldots1&lt;/script&gt;

&lt;p&gt;Virtebi algorithm uses the same schema as the Forward algorithm except for two differences:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It uses maximization in place of summation at the recursion and termination steps.&lt;/li&gt;
  &lt;li&gt;It keeps track of the arguments that maximize &lt;script type=&quot;math/tex&quot;&gt;\delta_t(i)&lt;/script&gt; for each &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, storing them in the N by T matrix &lt;script type=&quot;math/tex&quot;&gt;\Theta&lt;/script&gt;. This matrix is used to retrieve the optimal state sequence at the backtracking step.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Python implementation of virtebi algorithm&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# returns the most likely state sequence given observed sequence x
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# using the Viterbi algorithm
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;obs_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# backtrack
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;psi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To summarize, we can compute the following from HMM:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The marginalized likelihood function &lt;script type=&quot;math/tex&quot;&gt;P(Y \mid \lambda)&lt;/script&gt; from the forward or backward algorithm.&lt;/li&gt;
  &lt;li&gt;The posterior probability &lt;script type=&quot;math/tex&quot;&gt;\gamma_t(i) = P(s_t=i  \mid Y, \lambda)&lt;/script&gt; from the forward–backward algorithm.&lt;/li&gt;
  &lt;li&gt;The optimal state sequence &lt;script type=&quot;math/tex&quot;&gt;\hat{S} = \max_{s} P(S \mid Y, \lambda) = \max_{s} P(S, Y \mid  \lambda)&lt;/script&gt;from the Viterbi algorithm.&lt;/li&gt;
  &lt;li&gt;The segmental joint likelihood function &lt;script type=&quot;math/tex&quot;&gt;P(\hat{S},Y \mid \lambda)&lt;/script&gt; from the Viterbi algorithm.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These values are used in the decoding step and the training step of estimating model parameters &lt;script type=&quot;math/tex&quot;&gt;\lambda&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Conside the Bob-Alice example as described &lt;a href=&quot;https://en.wikipedia.org/wiki/Hidden_Markov_model#A_concrete_example&quot;&gt;here&lt;/a&gt;. Two friends, Alice and Bob, who live far apart from each other and who talk together daily over the telephone about what they did that day. Bob is only interested in three activities: walking in the park, shopping, and cleaning his apartment. The choice of what to do is determined exclusively by the weather on a given day. Alice has no definite information about the weather where Bob lives, but she knows general trends. Based on what Bob tells her he did each day, Alice tries to guess what the weather must have been like.&lt;/p&gt;

&lt;p&gt;Alice believes that the weather operates as a discrete Markov chain. There are two states, “Rainy” and “Sunny”, but she cannot observe them directly, that is, they are hidden from her. On each day, there is a certain chance that Bob will perform one of the following activities, depending on the weather: “walk”, “shop”, or “clean”. Since Bob tells Alice about his activities, those are the observations.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Rainy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Sunny'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;observations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'walk'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'shop'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'clean'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;#initial probability 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#Transmission probability 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#Emission probability
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Suppose Bob says walk, clean, shop, shop, clean, walk. What will Alice hears.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alice_hears&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;viterbi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Bob says:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;observ_bob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bob_says&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Alice hears:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;states_bob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alice_hears&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
    ('Bob says:', 'walk, clean, shop, shop, clean, walk')
    ('Alice hears:', 'Sunny, Rainy, Rainy, Rainy, Rainy, Sunny')
&lt;/blockquote&gt;

&lt;p&gt;The notebook with codes for the above example can be found in &lt;a href=&quot;https://github.com/sambaiga/HMM/blob/master/HMM%20Basics.ipynb&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;L. R. Rabiner, &lt;a href=&quot;http://www.cs.ucsb.edu/~cs281b/papers/HMMs%20-%20Rabiner.pdf&quot;&gt;A tutorial on hidden Markov models and selected applications in speech recognition&lt;/a&gt;, Proceedings of the IEEE, Vol. 77, No. 2, February 1989.&lt;/li&gt;
  &lt;li&gt;Shinji Watanabe, Jen-Tzung Chien, &lt;a href=&quot;https://books.google.co.tz/books/about/Bayesian_Speech_and_Language_Processing.html?id=rEzzCQAAQBAJ&amp;amp;printsec=frontcover&amp;amp;source=kp_read_button&amp;amp;redir_esc=y#v=onepage&amp;amp;q&amp;amp;f=false&quot;&gt;Bayesian Speech and Language Processing&lt;/a&gt;, Cambridge University Press, 2015.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.vocal.com/echo-cancellation/viterbi-algorithm-in-speech-enhancement-and-hmm/&quot;&gt;Viterbi Algorithm in Speech Enhancement and HMM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Nikolai Shokhirev, &lt;a href=&quot;http://www.shokhirev.com/nikolai/abc/alg/hmm/hmm.html&quot;&gt;Hidden Markov Models&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Learning Probabilistic Models</title><link href="https://sambaiga.github.io/ml/hmm/2017/04/25/probabilistic-models.html" rel="alternate" type="text/html" title="Learning Probabilistic Models" /><published>2017-04-25T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>https://sambaiga.github.io/ml/hmm/2017/04/25/probabilistic-models</id><content type="html" xml:base="https://sambaiga.github.io/ml/hmm/2017/04/25/probabilistic-models.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Given some data &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}=[x_1\ldots x_m]&lt;/script&gt;  that come from some probability density function characterized by
an unknown parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; . How can we find &lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}&lt;/script&gt;  that is the best estimator of &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;. For example suppose we have flipped a particular coin &lt;script type=&quot;math/tex&quot;&gt;100&lt;/script&gt;  times and landed head &lt;script type=&quot;math/tex&quot;&gt;N_H = 55&lt;/script&gt;  times and tails &lt;script type=&quot;math/tex&quot;&gt;N_T = 45&lt;/script&gt;  times. We are interested to know what is the probability that it will come-up head if we flip it again. In this case the behaviour of the coin can be summerized with parameter  &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;  the probability that a flip land head (H) which in this case is independent and identically ditributed Bernoulli distribution. The key question is how do we find parameter  &lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}&lt;/script&gt;  of this distribution that fit the data. This is called parameter estimation in which three approaches can be used:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Maximum-Likehood estimation&lt;/li&gt;
  &lt;li&gt;Bayesian parameter estimation and&lt;/li&gt;
  &lt;li&gt;Maximum a-posterior approximation&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;like-hood-and-log-likehood-function&quot;&gt;Like-hood and log-likehood function&lt;/h3&gt;

&lt;p&gt;Let firts define the &lt;strong&gt;like-hood function&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;L(\theta)&lt;/script&gt; which is the probability of the observed data as function of &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta) = P(x_1,\ldots x_m; \theta) = \prod_i^m P(x_i;\theta)&lt;/script&gt;

&lt;p&gt;The like-hood function indicates how likely each value of the parameter is to have generated the data. In the case of coin example above, the like-lihood is the probability of particular seqeuence of H and T generated:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta) = \theta ^{N_H}(1 - \theta ^{N_T})&lt;/script&gt;

&lt;p&gt;We also define the &lt;strong&gt;log-likelihood function&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}(\theta)&lt;/script&gt; which is the log of the likelihood function &lt;script type=&quot;math/tex&quot;&gt;L(\theta)&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(\theta) &amp;= \log L(\theta) \\
 &amp; = \log \prod_i^m P(x_i;\theta) \\
  &amp; = \sum_i^M P(x_i;\theta)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;For the above coin example the log-likelihood is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(\theta)= N_H\log\theta + N_T\log(1-\theta)&lt;/script&gt;

&lt;h2 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum-Likelihood Estimation&lt;/h2&gt;
&lt;p&gt;The main objective of maximum likelihood estimation (MLE) is to determine the value of &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; that is most likely to have generated the vector of observed data, &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; is assumed to be  fixed point (point-estimation). MLE achieve this by finding the parameter that maximize the probability of the observed data. The parameter &lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}&lt;/script&gt; is selected such that it maximize &lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}(\theta)&lt;/script&gt;:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta}=\arg\max_{\theta} \mathcal{L}(\theta)&lt;/script&gt;

&lt;p&gt;For the coin example the MLE is :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}(\theta)}{\partial \theta} &amp; = \frac{\partial }{\partial \theta}(N_H\log\theta + N_T\log(1-\theta) \\
 &amp;= \frac{N_H}{\theta} - \frac{N_T}{1-\theta}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Set &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}(\theta)}{\partial \theta} = 0&lt;/script&gt;  and  solve for &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; we obtain the MLE:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta} =\frac{N_H}{N_H + N_T}&lt;/script&gt;

&lt;p&gt;which is simply the fraction of flips that cameup head.&lt;/p&gt;

&lt;p&gt;Now suppose we are observing power-meta data which can be modelled as gaussian ditribution with mean &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt; and standard deviation &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt;. We can use MLE to estimate &lt;script type=&quot;math/tex&quot;&gt;\hat{\mu}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\hat{\sigma}&lt;/script&gt;. The log-likehood for gausian distribution is given as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}(\theta) &amp;= \sum_{i=1}^M \log \left[ \frac{1}{\sqrt{2} \pi \sigma} \exp \frac{-(x_i - \mu)}{2\sigma ^2}\right] \\
 &amp; = -\frac{M}{2}\log 2\pi - M\log \sigma - \frac{1}{2\sigma^2} \sum_i^M (x_i - \mu)^2
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Let find &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}(\theta)}{\partial \mu}&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}(\theta)}{\partial \sigma}&lt;/script&gt; and set  equal to zero.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}(\theta)}{\partial \mu} &amp;=  -\frac{1}{2\sigma^2} \sum_i^M \frac{\partial}{\partial \mu}(x_i - \mu)^2 \\
&amp; = \sum_i^M (x_i - \mu) = 0 \\
&amp;\Rightarrow \hat{\mu} = \frac{1}{M} \sum_{i=1}^M x_i
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;which is the mean of the observed values.&lt;/p&gt;

&lt;p&gt;Similary:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}(\theta)}{\partial \sigma} &amp;=  \frac{M}{\sigma} + \frac{1}{\sigma^3}\sum_i^M (x_i - \mu)^2 \\
&amp;\Rightarrow \hat{\sigma} = \sqrt{\frac{1}{M} \sum_{i=1}^M (x_i - \mu)^2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In the two examples above  we manged to obtain the exact maximum likelihood solution analytically. But this is not always the case, let’s consider how to compute the maximum likelihood estimate of the parameters of the gamma distribution, whose PDF is defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(x) = \frac{b^a}{\Gamma(a)}x^{x-1}\exp(-bx)&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\Gamma (a)&lt;/script&gt; is the gamma function which is the generalization of the factorial function to continous values given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Gamma(t) = \int_0^{-\infty} x^{t-1}\exp(-x) \,dx&lt;/script&gt;

&lt;p&gt;The model parameters for gamma distribution is &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt; both of which are &lt;script type=&quot;math/tex&quot;&gt;\geq 0&lt;/script&gt;. the log-likelihood is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \mathcal{L}( a, b) &amp; = \sum_{i=1}^M a\log b -\log \Gamma (a) + (a -1) \log x_i - bx_i \\
 &amp; = Ma\log b - M \log \Gamma (a) + (a - 1) \sum_{i=1}^M \log x_i - b \sum_{i=1}^M x_i
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;To get MLE we need employ gradient descent which consists of computing the derivatives:
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}}{\partial a}&lt;/script&gt; and 
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}}{\partial b}&lt;/script&gt; and then updating;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_{k+1}= a_k + \alpha \frac{\partial \mathcal{L}}{\partial a}&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{k+1}= b_k + \alpha \frac{\partial \mathcal{L}}{\partial b}&lt;/script&gt;

&lt;p&gt;where &lt;script type=&quot;math/tex&quot;&gt;\alpha&lt;/script&gt; is the learning rate.&lt;/p&gt;

&lt;h3 id=&quot;limitation-of-mle&quot;&gt;Limitation of MLE&lt;/h3&gt;

&lt;p&gt;Despite the fact that MLE is very powerful technique, it has a pitfall for little training data which can lead into seriously overfit. The most painful issue is when it assign a &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; probability to items that were never seen in the training data but which still might actually happen. Take an example if we flipped  a coin twice and &lt;script type=&quot;math/tex&quot;&gt;N_H = 2&lt;/script&gt;, the MLE of &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt;, the probability of H would be &lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;. This imply that we are considering it impossible for the coin to come up T. This problem is knowas &lt;em&gt;data sparsity&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;bayesian-parameter-estimation&quot;&gt;Bayesian Parameter Estimation&lt;/h2&gt;

&lt;p&gt;Unlike MLE which treat only the observation &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; as random variable and the parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; as a fixed point, the bayesian approach treat the parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; as random varibale as well with some known prior distribution. Let define the model for joint distribution &lt;script type=&quot;math/tex&quot;&gt;p(\theta, \mathcal{D})&lt;/script&gt; over parameter  &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and data &lt;script type=&quot;math/tex&quot;&gt;\mathcal{D}&lt;/script&gt;. To further define this joint distribution we aslo need the following two distribution:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A distribution of &lt;script type=&quot;math/tex&quot;&gt;P(\theta)&lt;/script&gt; knowas &lt;strong&gt;prior distribution&lt;/strong&gt; which is the probability of paratemeter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; availabe beforehand, and before making any additional observations. It account for everything you believed about the parameter &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; before observing the data. In practise choose prior that is computational convinient.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;strong&gt;likelihood&lt;/strong&gt; &lt;script type=&quot;math/tex&quot;&gt;P(\mathcal{D}\mid \theta)&lt;/script&gt; which is the probability of data given the parameter like in maximum likelihood.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this two distributions, we can compute the posterior distribution and the posterior predictive distribution. The posterior distribution &lt;script type=&quot;math/tex&quot;&gt;P(\theta \mid \mathcal{D})&lt;/script&gt; which correspond to uncertainty about &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; after observing the data given by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(\theta  \mid  \mathcal{D}) &amp;= \frac{P(\theta)p(\mathcal{D}  \mid  \theta)}{P(\mathcal{D})} &amp;= \frac{P(\theta)P(\mathcal{D} \mid  \theta)}{ \displaystyle \int P(\theta ^ {\prime} ) P(\mathcal{D} \mid  \theta ^{\prime})}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The denominator is usually considered as a normalizing constant and thus the posterior distribution become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\theta  \mid  \mathcal{D}) \propto P(\theta)P(\mathcal{D}  \mid \theta)&lt;/script&gt;

&lt;p&gt;On the other hand the posterior predictive distribution &lt;script type=&quot;math/tex&quot;&gt;P(\mathcal{D}^{\prime}\mid)\mathcal{D}&lt;/script&gt; is the distribution of future observation given past observation defined by:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(\mathcal{D}^{\prime} \mid \mathcal{D} )= \int P(\theta\mid \mathcal{D}) P(\mathcal{D}^{\prime} \mid \theta)&lt;/script&gt;

&lt;p&gt;Generaly the Bayesian approach to parameter estimation works as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First we need to formulate our knowledge about a situation by defining a distribution model which expresses qualitative aspects of our knowledge about the situation and then specify a prior probability distribution which expresses our subjective
beliefs and subjective uncertainty about the unknown parameters, before seeing the data.&lt;/li&gt;
  &lt;li&gt;Gather data&lt;/li&gt;
  &lt;li&gt;Obtain posterior knowledge that updates our beliefs by computing the posterior probability distribution which estimates the unknown
parameters.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let apply the bayesian estimation to the coin example in which we have specified the likelihood equal to &lt;script type=&quot;math/tex&quot;&gt;\theta^{N_H}(1-\theta)^{N_T}&lt;/script&gt;. We only required to specify the prior in which several approches can be used. One of the approach is relay upon lifetime experince of flipping coins in which most coins tend to be fair which implies &lt;script type=&quot;math/tex&quot;&gt;p(\theta) = 0.5&lt;/script&gt;. We can also use various distribution to specify prior density but in practise a most useful distribution is the &lt;strong&gt;beta distribution&lt;/strong&gt; parameterized by &lt;script type=&quot;math/tex&quot;&gt;a , b &gt; 0&lt;/script&gt; and defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta; a, b) = \frac{\Gamma (a + b)}{\Gamma(a) \Gamma (b)} \theta ^{a-1}(1-\theta ^{b - 1})&lt;/script&gt;

&lt;p&gt;From the above eqution it is clear that the first term (with all $\Gamma$)is just a normalizing constant and thus we can rewrite the beta distribution as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(\theta; a, b) \propto \theta ^{a-1}(1-\theta) ^{b - 1}&lt;/script&gt;

&lt;p&gt;Note the beta distribution has the following properties&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is centered around &lt;script type=&quot;math/tex&quot;&gt;\frac{a}{a + b}&lt;/script&gt; and it can be shown that if &lt;script type=&quot;math/tex&quot;&gt;\theta \sim \text{Beta}(a,b)&lt;/script&gt; then &lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}(\theta)=\frac{a}{a + b}&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;It becomes more peaked for larger values of &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;It become normal distribution when &lt;script type=&quot;math/tex&quot;&gt;a = b = 1&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now let compute the posterior and posterior predictive distribution&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
p(\theta | \mathcal{D}) &amp; \propto p(\theta)p(\mathcal{D} |\theta) \\
&amp; \propto \theta^{N_H}(1-\theta)^{N_T}\theta ^{a-1}(1-\theta) ^{b - 1} \\
&amp; = \theta ^{a-1+N_H}(1-\theta) ^{b - 1 + N_T}
\end{aligned} %]]&gt;&lt;/script&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Introduction</summary></entry><entry><title type="html">Introduction to Machine Learning - Classification.</title><link href="https://sambaiga.github.io/ml/2017/04/15/ml-classification.html" rel="alternate" type="text/html" title="Introduction to Machine Learning - Classification." /><published>2017-04-15T17:12:00+02:00</published><updated>2017-10-01T19:21:51+02:00</updated><id>https://sambaiga.github.io/ml/2017/04/15/ml-classification</id><content type="html" xml:base="https://sambaiga.github.io/ml/2017/04/15/ml-classification.html">&lt;p&gt;Previously we learned how to predict continuous-valued quantities as a linear function of input values.This post will describe a classification probem where the goal is to learn a mapping from inputs &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; to target &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;t \in \{1\ldots C \}&lt;/script&gt; with with &lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt; being the number of classes.If &lt;script type=&quot;math/tex&quot;&gt;C = 2&lt;/script&gt;, this is called binary classification (in which case we often assume &lt;script type=&quot;math/tex&quot;&gt;y \in \{0, 1\}&lt;/script&gt;; if &lt;script type=&quot;math/tex&quot;&gt;C &gt; 2&lt;/script&gt;, this is called multiclass classification.&lt;/p&gt;

&lt;p&gt;We will first consider binary classification problem in which the target classes &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; will be generated from 2 class distributions: blue (&lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;) and red (&lt;script type=&quot;math/tex&quot;&gt;t=0&lt;/script&gt;). Samples from both classes are sampled from their respective distributions. These samples are plotted in the figure below.&lt;/p&gt;

&lt;p&gt;Note that &lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is a &lt;script type=&quot;math/tex&quot;&gt;N \times 2&lt;/script&gt; matrix of individual input samples &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}_i&lt;/script&gt;, and that &lt;script type=&quot;math/tex&quot;&gt;\mathbf{t}&lt;/script&gt; is a corresponding &lt;script type=&quot;math/tex&quot;&gt;N \times 1&lt;/script&gt; vector of target values &lt;script type=&quot;math/tex&quot;&gt;t_i&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;logistic-regression&quot;&gt;Logistic Regression&lt;/h2&gt;

&lt;p&gt;With logistic regression the goal is to predict the target class &lt;script type=&quot;math/tex&quot;&gt;t&lt;/script&gt; from the input values &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;. The network is defined as having an input &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x} = [x_1, x_2]&lt;/script&gt; which gets transformed by the weights &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w} = [w_1, w_2]&lt;/script&gt; to generate the probability that sample &lt;script type=&quot;math/tex&quot;&gt;\mathbf{x}&lt;/script&gt; belongs to class &lt;script type=&quot;math/tex&quot;&gt;t=1&lt;/script&gt;. This probability &lt;script type=&quot;math/tex&quot;&gt;P(t=1\mid \mathbf{x},\mathbf{w})&lt;/script&gt; is represented by the output &lt;script type=&quot;math/tex&quot;&gt;y&lt;/script&gt; of the network computed as &lt;script type=&quot;math/tex&quot;&gt;y = \sigma(\mathbf{x} * \mathbf{w}^T)&lt;/script&gt;. &lt;script type=&quot;math/tex&quot;&gt;\sigma&lt;/script&gt; is the &lt;a href=&quot;http://en.wikipedia.org/wiki/Logistic_function&quot;&gt;logistic function&lt;/a&gt; and is defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sigma(z) = \frac{1}{1+e^{-z}}&lt;/script&gt;

&lt;p&gt;which squashes the predictions to be between 0 and 1 such that:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
P(t=1| \mathbf{x},\mathbf{w}) &amp;= y(\sigma(z))P(t=0\mid \mathbf{x},\mathbf{w})\\
 &amp;= 1 - P(t=1\mid \mathbf{x},\mathbf{w}) = 1 - y(\sigma(z))
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The loss function for logistic function is called crossentropy and defined as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{CE}(y,t)=\begin{cases} -\log y \quad \text{if } t = 1\\ -\log (1-y) \quad \text{if } t = 0
\end{cases}&lt;/script&gt;

&lt;p&gt;The crossentropy can be written in other form as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{CE}(y,t)= -t \log y -(1-t)\log(1-y)&lt;/script&gt;

&lt;p&gt;When we combine the logistic activation function with cross-entropy loss, we get logistic regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
z &amp; = \mathbf{w^Tx + b}\\\ y &amp; = \sigma(z)\\\ \mathcal{L}_{CE}(y,t) &amp;= -t \log y -(1-t)\log(1-y)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The cost function with respect to the model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (i.e. the weights and bias) is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\varepsilon_{\theta} &amp; = \frac{1}{N}\sum_{i=1}^N \mathcal{L}_{CE}(y,t)\\\ &amp; = \frac{1}{N}\sum_{i=1}^N \left(-t^{(i)} \log y^{(i)} -(1-t^{(i)})\log(1-y^{(i)})\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;which can be implemented in python as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Define the cost function
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;gradient-descent-for-logistic-function&quot;&gt;Gradient Descent for Logistic Function&lt;/h3&gt;

&lt;p&gt;To derive the gradient descent updates, we’ll need the partial derivatives of the cost function. We’ll do this by applying the Chain Rule twice: first to compute 
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial z}&lt;/script&gt; 
and then again to compute &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial w_j}&lt;/script&gt; But first, let’s find 
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial y}{\partial z}&lt;/script&gt;.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial y}{ \partial z}  = \frac{e^{-z}}{(1 + e^{-z})^2}= y(1-y)&lt;/script&gt;

&lt;p&gt;Now for the Chain Rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial z} &amp; =\frac{\partial \mathcal{L}_{CE}}{\partial y}\frac{\partial y}{ \partial z}\\\ &amp; = \left(\frac{-t}{y} + \frac{1-t}{1-y}  \right) y(1-y)\\\ &amp;= y - t
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Similary:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial w_j} &amp; =\frac{\partial \mathcal{L}_{CE}}{\partial z}\frac{\partial z}{ \partial w_j}\\\ &amp;  =\frac{\partial \mathcal{L}_{CE}}{\partial z} x_j\\\ &amp;= (y - t)x_j
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We can also obtain &lt;script type=&quot;math/tex&quot;&gt;\frac{\partial \mathcal{L}_{CE}}{\partial b}&lt;/script&gt; as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial b} &amp;= \frac{\partial \mathcal{L}_{CE}}{\partial z}\frac{\partial z}{\partial b}\\ &amp; = (y-t)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The gradient descent algorithm works by taking the derivative of the cost function &lt;script type=&quot;math/tex&quot;&gt;\varepsilon_{\theta}&lt;/script&gt; with respect to the parameters, and updates the parameters in the direction of the negative gradient.The parameter &lt;script type=&quot;math/tex&quot;&gt;\mathbf{w}&lt;/script&gt; is iteratively updated by taking steps proportional to the negative of the gradient:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{w_{k+1}} = \mathbf{ w_k }- \alpha \frac{\partial \mathbf{\varepsilon}}{\partial \mathbf{w}}&lt;/script&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial \varepsilon} &amp;= \frac{\partial \varepsilon }{\partial \mathcal{L}_{CE}}\cdot\frac{\partial \mathcal{L}_{CE}}{\partial \mathbf{w}}\\ &amp;= \frac{1}{N} \mathbf{x^T(y - t)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;which can be implemented in python as follows:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#gradient
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;solve_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dw&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w_cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Stopping Condition
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Converged.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Iteration: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d - cost: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%.4&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_k&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;   
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let us apply the above concept in the following example. Consider the case we want to predict whether a student with certain pass mark can be admitted or not.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# load dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/admission.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;grade1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;grade2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;remark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The data-preprosessing is done using the following python code:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'grade1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'grade2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'remark'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;targetVal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;admission&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targetVal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Standardize the features
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Add bias term to feature data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;featureVal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# randomly separate data into training and test data
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We use the solve_gradient function defined before to find the parameter for logistic regression&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;solve_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now that you learned the parameters of the model, you can use the model to predict whether a particular student will be admited.&lt;/p&gt;

&lt;p&gt;Let define the  prediction function that only  1 or 0 depending on the predicted class&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;around&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To find the accuracy of the model:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;p_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Test Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Train Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;After running the above codes we found that our model achieve  a training accuracy of &lt;script type=&quot;math/tex&quot;&gt;91.25&lt;/script&gt; and a test accuracy of &lt;script type=&quot;math/tex&quot;&gt;85&lt;/script&gt; percents.&lt;/p&gt;

&lt;h2 id=&quot;multiclass-classification&quot;&gt;Multiclass classification&lt;/h2&gt;

&lt;p&gt;So far we’ve talked about binary classification, but most classifcation problems involve more than two categories. Fortunately, this doesn’t require any new ideas: everything pretty much works by analogy with the binary
case. The first question is how to represent the targets. We could represent them as integers, but it’s more convenient to use indicator vectors, or a one-of-K encoding.&lt;/p&gt;

&lt;p&gt;Since there are &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; outputs and &lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt; inputs, the linear function requires &lt;script type=&quot;math/tex&quot;&gt;K \times D&lt;/script&gt; matrix as well as &lt;script type=&quot;math/tex&quot;&gt;K&lt;/script&gt; dimensional bias vector. We use &lt;strong&gt;softmax function&lt;/strong&gt; which is the multivariate generalization given as:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_k =  softmax(z_1 \ldots z_k) = \frac{e^{z_k}}{\sum_k e^{z_k}}&lt;/script&gt;

&lt;p&gt;and can be implented in python as&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Finally, the loss function (cross-entropy) for multiple-output case can be generalized as follows:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\mathcal{L}_{CE}(y,t) &amp;= -\sum_{k=1}^K t_k \log y_k\\ &amp;= -\mathbf{t^T}\log\mathbf{y}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Combining these things together, we get multiclass logistic regression:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} 
\mathbf{z} &amp;= \mathbf{wx + b} \\ \mathbf{y} &amp;= softmax(\mathbf{z})\\ \mathcal{L}_{CE}(y,t) &amp;=-\mathbf{t^T}\log\mathbf{y} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h2 id=&quot;gradient-descent-for-multiclass-logisitc-regression-for-multiclass-logistic-regression&quot;&gt;Gradient Descent for Multiclass Logisitc Regression for Multiclass logistic regression:&lt;/h2&gt;

&lt;p&gt;Let consider the derivative with respect to the loss:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;= \frac{\partial }{\partial w_{kj}} \left(-\sum_l t_l \log(y_l)\right) \\ &amp;= -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Normally in calculus we have the rule:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial y_l}{\partial w_{kj}} &amp;= \sum_m \frac{\partial y_l}{\partial z_m} \frac{\partial z_m}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;But &lt;script type=&quot;math/tex&quot;&gt;w_{kj}&lt;/script&gt; is independent of &lt;script type=&quot;math/tex&quot;&gt;z_m&lt;/script&gt; for &lt;script type=&quot;math/tex&quot;&gt;m \ne k&lt;/script&gt;, so&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial y_l}{\partial w_{kj}} &amp;= \frac{\partial y_l}{\partial z_k} \frac{\partial z_k}{\partial w_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;AND&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial z_k}{\partial w_{kj}} = x_j&lt;/script&gt;

&lt;p&gt;Thus&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;=  -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k} \frac{\partial z_k}{\partial w_{kj}} \\
 &amp;= -\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k} x_j \\
  &amp;= x_j (-\sum_l \frac{t_l}{y_l} \frac{\partial y_l}{\partial z_k}) \\
   &amp;= x_j \frac{\partial {\mathcal L}_\text{CE}}{\partial z_k} 
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Now consider derivative with respect to &lt;script type=&quot;math/tex&quot;&gt;z_k&lt;/script&gt; we can show (on board) that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\partial y_l}{\partial z_k} = y_k (I_{k,l} - y_l)&lt;/script&gt;

&lt;p&gt;Where &lt;script type=&quot;math/tex&quot;&gt;I_{k,l} = 1&lt;/script&gt; if &lt;script type=&quot;math/tex&quot;&gt;k=l&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; otherwise.&lt;/p&gt;

&lt;p&gt;Therefore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial z_k} &amp;= -\sum_l \frac{t_l}{y_l} (y_k (I_{k,l} - y_l)) \\ &amp;=-\frac{t_k}{y_k} y_k(1 - y_k) - \sum_{l \ne k} \frac{t_l}{y_l} (-y_k y_l) \\
 &amp;= - t_k(1 - y_k) + \sum_{l \ne k} t_l y_k \\
  &amp;= -t_k + t_k y_k + \sum_{l \ne k} t_l y_k \\
   &amp;= -t_k + \sum_{l} t_l y_k \\
    &amp;= -t_k + y_k \sum_{l} t_l  \\
     &amp;= -t_k + y_k \\
      &amp;= y_k - t_k
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Putting it all together&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial {\mathcal L}_\text{CE}}{\partial w_{kj}} &amp;= x_j (y_k - t_k)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In vectorization form it become:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\frac{\partial \mathcal {L}_{CE}}{\partial {\mathbf W}} = (\mathbf{y} - \mathbf{t}) \mathbf{x}^T 
\end{aligned}&lt;/script&gt;

&lt;h3 id=&quot;cross-entropy-cost-function&quot;&gt;Cross-entropy cost function&lt;/h3&gt;

&lt;p&gt;The cross entropy cost function for multiclass classification is given with respect to the model parameters &lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (i.e. the weights and bias) is therefore:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\varepsilon_{\theta} &amp; = \frac{1}{N}\sum_{i=1}^N \mathcal{L}_{CE}(y,t)\\
 &amp; = \frac{-1}{N}\sum_{i=1}^N \sum_{k=1}^K t_k \log y_k
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The gradient descent algorithm will be:
&lt;script type=&quot;math/tex&quot;&gt;\mathbf{w_{k+1}} = \mathbf{ w_k }- \alpha \frac{\partial \mathbf{\varepsilon}}{\partial \mathbf{w}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;where:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\frac{\partial \mathcal{L}_{CE}}{\partial \varepsilon} &amp;= \frac{\partial \varepsilon }{\partial \mathcal{L}_{CE}}\cdot\frac{\partial \mathcal{L}_{CE}}{\partial \mathbf{w}}\\
 &amp;= \frac{1}{N} \mathbf{x^T(y - t)}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The jupyter notebook for this post can be found &lt;a href=&quot;https://github.com/sambaiga/PythonML/blob/master/MLwithPython/Classification%20.ipynb&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/&quot;&gt;CSC321 Intro to Neural Networks and Machine Learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/&quot;&gt;Supervised and Unsupervised Machine Learning Algorithms&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Anthony Faustine</name></author><summary type="html">Previously we learned how to predict continuous-valued quantities as a linear function of input values.This post will describe a classification probem where the goal is to learn a mapping from inputs to target such that with with being the number of classes.If , this is called binary classification (in which case we often assume ; if , this is called multiclass classification.</summary></entry></feed>